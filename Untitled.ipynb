{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f78e3dd9",
   "metadata": {},
   "source": [
    "# Credit Profile (Two-wheeler loan) Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f460d3",
   "metadata": {},
   "source": [
    "# 2. Data Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863ab81",
   "metadata": {},
   "source": [
    "This dataset provides a comprehensive overview of potential loan applicants' profiles, specifically tailored for the Indian demographic. It encapsulates a range of features, from basic demographics to financial details, that can be instrumental in assessing the creditworthiness of an individual.\n",
    "\n",
    "Age:\n",
    "Type: Integer\n",
    "Description: Represents the age of the applicant. Indicates the applicant's maturity level.\n",
    "Range: 18 to 70\n",
    "\n",
    "Gender:\n",
    "Type: Categorical\n",
    "Description: Gender of the applicant.\n",
    "Categories: Male, Female, Other\n",
    "\n",
    "Income:\n",
    "Type: Integer\n",
    "Description: The applicant's income, which is critical in assessing their ability to repay the loan.\n",
    "Range: Multiples of 1000's\n",
    "\n",
    "Credit Score:\n",
    "Type: Integer\n",
    "Description: A score quantifying the applicant's creditworthiness based on their credit history.\n",
    "Range: 300 to 850\n",
    "\n",
    "Credit History Length:\n",
    "Type: Integer\n",
    "Description: Represents the number of months since the applicant's first credit line. Indicates the applicant's experience with credit management.\n",
    "Units: Months\n",
    "\n",
    "Number of Existing Loans:\n",
    "Type: Integer\n",
    "Description: The number of loans the applicant currently has.\n",
    "Range: 0 to 10\n",
    "\n",
    "Loan Amount:\n",
    "Type: Integer\n",
    "Description: The amount of money the applicant is requesting.\n",
    "Range: 0 to 150,000\n",
    "\n",
    "Loan Tenure:\n",
    "Type: Integer\n",
    "Description: The number of months the applicant wants to repay the loan over.\n",
    "Units: Months\n",
    "\n",
    "Existing Customer:\n",
    "Type: Categorical\n",
    "Description: Whether the applicant is an existing customer of the finance company.\n",
    "Categories: Yes, No\n",
    "\n",
    "State:\n",
    "Type: Categorical\n",
    "Description: The state in India where the applicant resides.\n",
    "Categories: Maharashtra, Delhi, Karnataka, Tamil Nadu, West Bengal, Uttar Pradesh, Gujarat, Rajasthan, Kerala, Telangana, etc.\n",
    "\n",
    "City:\n",
    "Type: Categorical\n",
    "Description: The city or village in India where the applicant resides.\n",
    "Categories: Mumbai, Pune, New Delhi, Bengaluru, Chennai, Kolkata, Ahmedabad, Jaipur, Kochi, Hyderabad, and various villages.\n",
    "\n",
    "LTV Ratio:\n",
    "Type: Float\n",
    "Description: The loan-to-value ratio, represents the ratio of the loan amount to the appraised value of the asset (typically a house). Higher LTVs can indicate higher risk.\n",
    "Range: 40% to 95%\n",
    "\n",
    "Employment Profile:\n",
    "Type: Categorical\n",
    "Description: General employment category of the applicant.\n",
    "Categories: Salaried, Self-Employed, Freelancer, Unemployed, Student\n",
    "\n",
    "Occupation:\n",
    "Type: Categorical\n",
    "Description: Specific occupation or job title of the applicant.\n",
    "Categories: Software Engineer, Doctor, Teacher, Business Owner, Writer, etc.\n",
    "\n",
    "Profile Score:\n",
    "Type: Integer\n",
    "Description: A score ranging from 0 to 100 represents the overall profile of the applicant based on the actual loan repayment data. Higher values indicate better profiles.\n",
    "Range: 0 to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af7d00bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "import pylab\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#loading the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75268bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/01 19:20:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/10/01 19:20:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MySparkApp\") \\\n",
    "    .getOrCreate()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc6c16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 3.81 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%time\n",
    "df=spark.read.csv(\"credit_data.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeedc82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279856"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd85ccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/01 19:20:43 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 5:========>                                                  (1 + 6) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------+-----------------+------------------+---------------------+------------------------+------------------+------------------+-----------------+-----------+---------+-----------------+------------------+-----------------+----------+\n",
      "|summary|              Age|Gender|           Income|      Credit Score|Credit History Length|Number of Existing Loans|       Loan Amount|       Loan Tenure|Existing Customer|      State|     City|        LTV Ratio|Employment Profile|    Profile Score|Occupation|\n",
      "+-------+-----------------+------+-----------------+------------------+---------------------+------------------------+------------------+------------------+-----------------+-----------+---------+-----------------+------------------+-----------------+----------+\n",
      "|  count|           279856|279856|           279856|            279856|               279856|                  279856|            279856|            279856|           279856|     279856|   279856|           279856|            279856|           279856|    279856|\n",
      "|   mean|44.00521696872677|  null|76499.16385569722|  582.953772654508|   307.96514636098567|       4.701693013549826|105795.34277271168|133.34065376479333|             null|       null|     null|71.64310107538067|              null| 77.3501550797553|      null|\n",
      "| stddev| 15.3110509208066|  null|42875.57519280222|163.07675415692245|   175.08326792343792|      2.9803507697460496|40458.370929219716| 96.06413248745437|             null|       null|     null|16.86578456606675|              null|24.50919563949047|      null|\n",
      "|    min|               18|Female|             9000|               300|                    6|                       0|              5294|                12|               No|      Delhi|Ahmedabad|             40.0|        Freelancer|                0|    Banker|\n",
      "|    max|               70| Other|           209000|               850|                  611|                      10|            150000|               359|              Yes|West Bengal|  Udaipur|             95.0|        Unemployed|              100|    Writer|\n",
      "+-------+-----------------+------+-----------------+------------------+---------------------+------------------------+------------------+------------------+-----------------+-----------+---------+-----------------+------------------+-----------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/01 19:20:47 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "865b8cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Income: integer (nullable = true)\n",
      " |-- Credit Score: integer (nullable = true)\n",
      " |-- Credit History Length: integer (nullable = true)\n",
      " |-- Number of Existing Loans: integer (nullable = true)\n",
      " |-- Loan Amount: integer (nullable = true)\n",
      " |-- Loan Tenure: integer (nullable = true)\n",
      " |-- Existing Customer: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- LTV Ratio: double (nullable = true)\n",
      " |-- Employment Profile: string (nullable = true)\n",
      " |-- Profile Score: integer (nullable = true)\n",
      " |-- Occupation: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#column data types\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af2a70b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns with all the same values\n",
    "columns_to_drop = []\n",
    "for column in df.columns:\n",
    "    if len(df.select(column).distinct().collect()) <= 1:\n",
    "        columns_to_drop.append(column)\n",
    "columns_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54ee31f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns: ['Age', 'Gender', 'Income', 'Credit Score', 'Credit History Length', 'Number of Existing Loans', 'Loan Amount', 'Loan Tenure', 'Existing Customer', 'State', 'City', 'LTV Ratio', 'Employment Profile', 'Profile Score', 'Occupation']\n",
      "Number of rows: 279856\n"
     ]
    }
   ],
   "source": [
    "# Drop the identified columns\n",
    "df = df.drop(*columns_to_drop)\n",
    "\n",
    "# Get the list of remaining columns\n",
    "remaining_columns = df.columns\n",
    "\n",
    "# Count the number of rows\n",
    "num_rows = df.count()\n",
    "print(\"Remaining columns:\", remaining_columns)\n",
    "print(\"Number of rows:\", num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a94f3eb",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e09e8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column : 'Age' has 0 null values.\n",
      "Column : 'Gender' has 0 null values.\n",
      "Column : 'Income' has 0 null values.\n",
      "Column : 'Credit Score' has 0 null values.\n",
      "Column : 'Credit History Length' has 0 null values.\n",
      "Column : 'Number of Existing Loans' has 0 null values.\n",
      "Column : 'Loan Amount' has 0 null values.\n",
      "Column : 'Loan Tenure' has 0 null values.\n",
      "Column : 'Existing Customer' has 0 null values.\n",
      "Column : 'State' has 0 null values.\n",
      "Column : 'City' has 0 null values.\n",
      "Column : 'LTV Ratio' has 0 null values.\n",
      "Column : 'Employment Profile' has 0 null values.\n",
      "Column : 'Profile Score' has 0 null values.\n",
      "Column : 'Occupation' has 0 null values.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "null_counts = []\n",
    "\n",
    "# Iterate over all columns in the DataFrame\n",
    "for col_name in df.columns:\n",
    "    # Count the number of null values for each column\n",
    "    null_count = df.where(col(col_name).isNull()).count()\n",
    "    # Append the result to the list\n",
    "    null_counts.append((col_name, null_count))\n",
    "\n",
    "# Display the null counts for each column\n",
    "for col_name, count in null_counts:\n",
    "    print(f\"Column : '{col_name}' has {count} null values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "325555f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select([col(column).alias(column.strip()) for column in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "165cc584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Income: integer (nullable = true)\n",
      " |-- Credit Score: integer (nullable = true)\n",
      " |-- Credit History Length: integer (nullable = true)\n",
      " |-- Number of Existing Loans: integer (nullable = true)\n",
      " |-- Loan Amount: integer (nullable = true)\n",
      " |-- Loan Tenure: integer (nullable = true)\n",
      " |-- Existing Customer: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- LTV Ratio: double (nullable = true)\n",
      " |-- Employment Profile: string (nullable = true)\n",
      " |-- Profile Score: integer (nullable = true)\n",
      " |-- Occupation: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33389ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a9c31a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols=[]\n",
    "catorical_cols=[]\n",
    "for cols in df.columns:\n",
    "    (catorical_cols.append(cols) if df.select(cols).dtypes[0][1]=='string' else numerical_cols.append(cols))\n",
    "df_num=df.select(numerical_cols)\n",
    "df_cat=df.select(catorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bdabc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------------+---------------------+------------------------+-----------+-----------+-----------------+-------------+\n",
      "|Age|Income|Credit Score|Credit History Length|Number of Existing Loans|Loan Amount|Loan Tenure|        LTV Ratio|Profile Score|\n",
      "+---+------+------------+---------------------+------------------------+-----------+-----------+-----------------+-------------+\n",
      "| 31| 36000|         604|                  487|                       5|     109373|        221|90.94342996168837|           77|\n",
      "| 25| 50000|         447|                  386|                       2|     150000|         89|91.13525304169426|           43|\n",
      "| 62|178000|         850|                  503|                      10|      69099|        110|             40.0|           90|\n",
      "| 69| 46000|         668|                  349|                       6|     150000|        148|87.39336509478201|           86|\n",
      "| 52|132000|         601|                  553|                       5|     150000|        157|66.15875689399839|           90|\n",
      "+---+------+------------+---------------------+------------------------+-----------+-----------+-----------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_num.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55d1b9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9700399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/01 19:21:15 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/10/01 19:21:15 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "selected_columns=list(df_num.columns)\n",
    "vector_Assembler=VectorAssembler(inputCols=df_num.columns,outputCol='features')\n",
    "df_assembled=vector_Assembler.transform(df_num).select('features')\n",
    "#print(df_assembled.show(5))\n",
    "correlation_matrix = Correlation.corr(df_assembled, \"features\").head()\n",
    "#print(correlation_matrix)\n",
    "correlation_matrix = correlation_matrix[0].toArray()[selected_columns.index('Loan Amount')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "472ab016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: 26.77\n",
      "Income: 38.77\n",
      "Credit Score: 8.43\n",
      "Credit History Length: 0.17\n",
      "Number of Existing Loans: 8.41\n",
      "Loan Amount: 100.00\n",
      "Loan Tenure: 4.65\n",
      "LTV Ratio: -3.02\n",
      "Profile Score: 6.93\n"
     ]
    }
   ],
   "source": [
    "columns = ['Column', 'Correlation with Loan Amount']\n",
    "data = dict(zip(selected_columns, correlation_matrix))\n",
    "for column, correlation in data.items():\n",
    "    print(f\"{column}: {correlation*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc5b4ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------------+---------------------+------------------------+-----------+-----------+-----------------+---------+---------+-----------------+------------------+-------------+-----------------+\n",
      "|Age|Gender|Income|Credit Score|Credit History Length|Number of Existing Loans|Loan Amount|Loan Tenure|Existing Customer|    State|     City|        LTV Ratio|Employment Profile|Profile Score|       Occupation|\n",
      "+---+------+------+------------+---------------------+------------------------+-----------+-----------+-----------------+---------+---------+-----------------+------------------+-------------+-----------------+\n",
      "| 31|  Male| 36000|         604|                  487|                       5|     109373|        221|               No|Karnataka|   Mysuru|90.94342996168837|          Salaried|           77|           Doctor|\n",
      "| 25|  Male| 50000|         447|                  386|                       2|     150000|         89|               No|Karnataka|Bengaluru|91.13525304169426|          Salaried|           43|Software Engineer|\n",
      "+---+------+------+------------+---------------------+------------------------+-----------+-----------+-----------------+---------+---------+-----------------+------------------+-------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3b3aab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'Gender',\n",
       " 'Income',\n",
       " 'Credit Score',\n",
       " 'Credit History Length',\n",
       " 'Number of Existing Loans',\n",
       " 'Loan Amount',\n",
       " 'Loan Tenure',\n",
       " 'Existing Customer',\n",
       " 'State',\n",
       " 'City',\n",
       " 'LTV Ratio',\n",
       " 'Employment Profile',\n",
       " 'Profile Score',\n",
       " 'Occupation']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b7a4c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>133145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Other</td>\n",
       "      <td>13962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>132749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   count\n",
       "0  Female  133145\n",
       "1   Other   13962\n",
       "2    Male  132749"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Gender=df.groupBy(col('Gender').alias('Gender')).count()\n",
    "df_Gender=df_Gender.toPandas()\n",
    "df_Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1143cad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "plt.pie(df_Gender['count'],labels=df_Gender['Gender'],autopct='%.2f%%',radius=1\n",
    "       ,wedgeprops=dict(width=.5)\n",
    "        ,pctdistance=.75\n",
    "       );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b1bd49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+-------------+------------------+------------------+-----------------+\n",
      "|Gender|Existing Customer|        State|              City|Employment Profile|       Occupation|\n",
      "+------+-----------------+-------------+------------------+------------------+-----------------+\n",
      "|  Male|               No|    Karnataka|            Mysuru|          Salaried|           Doctor|\n",
      "|  Male|               No|    Karnataka|         Bengaluru|          Salaried|Software Engineer|\n",
      "| Other|              Yes|Uttar Pradesh|            Kanpur|          Salaried|           Banker|\n",
      "|Female|              Yes|    Karnataka|         Bengaluru|     Self-Employed|       Contractor|\n",
      "|  Male|               No|    Karnataka|            Mysuru|          Salaried|          Teacher|\n",
      "|Female|              Yes|   Tamil Nadu|        Coimbatore|     Self-Employed|       Contractor|\n",
      "|  Male|               No|Uttar Pradesh|           Lucknow|     Self-Employed|           Farmer|\n",
      "| Other|               No|  West Bengal|           Kolkata|          Salaried|           Banker|\n",
      "|  Male|              Yes|    Rajasthan|            Jaipur|        Freelancer|           Writer|\n",
      "|  Male|               No|  Maharashtra|            Nagpur|          Salaried|           Banker|\n",
      "|  Male|               No|   Tamil Nadu|        Coimbatore|     Self-Employed|       Shopkeeper|\n",
      "|  Male|              Yes|      Gujarat|             Surat|        Freelancer|           Writer|\n",
      "|Female|               No|    Telangana|         Hyderabad|        Freelancer|     Photographer|\n",
      "|Female|               No|   Tamil Nadu|           Chennai|           Student|          Student|\n",
      "|Female|               No|       Kerala|Thiruvananthapuram|          Salaried|    Civil Servant|\n",
      "|Female|               No|    Rajasthan|           Udaipur|          Salaried|    Civil Servant|\n",
      "|  Male|              Yes|    Karnataka|            Mysuru|     Self-Employed|       Contractor|\n",
      "|  Male|               No|    Rajasthan|           Udaipur|     Self-Employed|       Contractor|\n",
      "|Female|               No|  West Bengal|           Kolkata|          Salaried|Software Engineer|\n",
      "|Female|              Yes|  West Bengal|           Kolkata|          Salaried|          Teacher|\n",
      "+------+-----------------+-------------+------------------+------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2f82801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Existing_Customer</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>173952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>105904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Existing_Customer   count\n",
       "0                No  173952\n",
       "1               Yes  105904"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Existing_Customer=df.groupBy(col('Existing Customer').alias('Existing_Customer')).count()\n",
    "df_Existing_Customer=df_Existing_Customer.toPandas()\n",
    "df_Existing_Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dfe8d374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "plt.pie(df_Existing_Customer['count'],labels=df_Existing_Customer['Existing_Customer'],autopct='%.2f%%',radius=1\n",
    "       ,wedgeprops=dict(width=.5)\n",
    "        ,pctdistance=.75\n",
    "       );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "355c911c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,3))\n",
    "\n",
    "df_Employment_Profile=df.groupBy(col('Employment Profile').alias('Employment_Profile')).count()\n",
    "df_Employment_Profile=df_Employment_Profile.orderBy('count',ascending=False)\n",
    "df_Employment_Profile=df_Employment_Profile.toPandas()\n",
    "df_Employment_Profile['count']=round(df_Employment_Profile['count']/sum(df_Employment_Profile['count'])*100,2)\n",
    "df_Employment_Profile=df_Employment_Profile.head(10)\n",
    "sns.barplot(y=df_Employment_Profile['Employment_Profile'],x=df_Employment_Profile['count']);\n",
    "for i, val in enumerate(df_Employment_Profile.index):\n",
    "    y = df_Employment_Profile['count'].loc[val].sum()\n",
    "    plt.text( y+1, i+.2,str(round(y))+'%', ha=\"center\",fontsize = 15,         color ='black')\n",
    "plt.ylabel('Employment Profile',fontsize=10);\n",
    "plt.xlabel('% of Customers',fontsize=10);\n",
    "# Add legend outside the plot\n",
    "plt.legend(bbox_to_anchor=(1, 1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "56ac89db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABNsAAAHOCAYAAAChNg9eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAACFlUlEQVR4nOzdeZyN5eP/8fcxZsbsjG0GY5BlkmyVnUGYyJZEyBIpO5GtZC0qax8kKlJ2oSzZyyAiW8hYkq3s21hnLHP9/vCb83XMdjhnzOL1fDzOo+a+r/u+rvvc59z3fd6u+74sxhgjAAAAAAAAAA7LkNINAAAAAAAAANILwjYAAAAAAADASQjbAAAAAAAAACchbAMAAAAAAACchLANAAAAAAAAcBLCNgAAAAAAAMBJCNsAAAAAAAAAJyFsAwAAAAAAAJwkY0o3ILWKiYnRyZMn5ePjI4vFktLNAQAAAAAAQAoyxujq1avKlSuXMmRIuP8aYVsCTp48qaCgoJRuBgAAAAAAAFKREydOKE+ePAnOJ2xLgI+Pj6R7b6Cvr28KtwYAAAAAAAAp6cqVKwoKCrJmRgkhbEtA7K2jvr6+qSps2759u1avXq2tW7dqy5YtOnnypNzd3RUVFZXoct99950mTJigffv2yc3NTeXKldOAAQNUoUKFOGWjoqLUq1cvzZ07Vzdv3tSLL76o8ePHKzg4OE7ZyMhIFSlSRNWqVdPs2bOdtp0AAAAAAACpUVKPGyNsS2OGDRumn3766aGW6dmzp8aOHSsPDw/VqlVLUVFRWr16tVatWqX58+frlVdesSnfvXt3TZkyRaVLl1b27Nm1dOlSHT58WLt375aLi4tN2YEDB+r69esaNWqUw9sGAAAAAACQ1jEaaRpTvnx5DRw4UEuWLNHp06eTLP/LL79o7Nixypo1q/7880/9+OOPWrFihdavXy8XFxe9+eabunTpkrX8qVOnNHXqVNWuXVvbtm3TihUrNGzYMO3bt0+LFi2yWffevXv1xRdf6MMPP1Tu3Lmdvq0AAAAAAABpDWFbGtO3b18NGTJEdevWVc6cOZMsP3r0aEnSgAEDVKhQIev08uXLq0OHDoqMjNTUqVOt0/fu3as7d+6oVatW1m6Rbdu2lSTt2rXLZt1dunTRU089pXfffdfRzQIAAAAAAEgXCNvSsaioKK1du1aS1Lhx4zjzY6ctWbLEOi22l1uWLFms02L//+LFi9Zps2bNUnh4uMaPHy9XV1fnNx4AAAAAAMBJjDG6ffu2oqKiEnzdvn1bxhiH6+KZbenY/v37FR0drezZs8c7JG3p0qUlSbt377ZOy5s3ryTp0KFDCgsLkyQdPHhQkqwDJFy7dk29e/fWq6++qpo1aybrNgAAAAAAADji1q1bOnXqlG7cuJFkWU9PTwUGBsrNze2R66NnWzp2/PhxSYo3aJMkLy8vZc6cWZcuXdLVq1clSSVLllRgYKDGjBmjvXv36syZM+rTp48sFotq164tSRo6dKguX76sMWPGPJ4NSee2b9+uTz75RI0aNVLu3LllsViUKVOmJJf77rvvVKZMGXl7e8vf31916tTRpk2b4i0bFRWlzp07K1u2bPLy8lL9+vV17NixeMtGRkYqICBAzZo1c2i7AAAAAABIaTExMTpy5Ihu376tXLlyKV++fMqfP3+cV758+ZQrVy7dvn1bR44cUUxMzCPXSdiWjl27dk3SvVQ2IV5eXjZlM2XKpJEjR+ro0aN69tlnFRAQoJUrV6pDhw4qXry4Dhw4oHHjxun999+39oKTpJs3bzqlq+WTaNiwYerfv78WLVqkkydP2rVMz5491bp1a+3du1c1atRQmTJltHr1alWpUiXOQBbSvRFmv/jiCwUHB6ty5cpaunSp6tSpo7t378YpywizjiE8BQAAAIDU49atW4qJiVGuXLnk5+cnDw8PZcqUKc7Lw8NDfn5+ypUrl2JiYnTr1q1HrpOwLR2LDb9iBzpIrMz9WrRood9++03vvvuuOnbsqPnz52vixImSpK5duypv3rx67733JElz5sxRvnz55OnpqSxZsmjAgAEOpb9PIkaYTV8IT9MXwlMAAAAgfciQwb4IzN5yiTJpUHh4uKlbt64JDAw0ksyiRYts5sfExJhBgwaZwMBAkylTJhMaGmr27t37UHVERkYaSSYyMtKJLXc+Scbd3T3eeT/99JORZEqVKpXg8pkzZzaSzJUrV5Ks64cffjCSzNKlS40xxmzbts1YLBbz0ksvmR9//NG8++67RpL5/PPPH21jYIxJfJ8aY0ydOnWMJDN27Ng487p162YkmVGjRlmnrVq1ykgys2fPtk47efKkkWQ++OADm+VDQ0NNkSJFzK1btxzfkCfUJ598YgYOHGiWLFliTp8+neT+XLt2rZFksmbNag4ePGidvmnTJuPm5mb8/PzMxYsXrdNPnjxpMmbMaGrXrm1iYmKMMcZ89NFHRpKZP3++zbr37NljMmbMaD799FMnb+WTo0GDBkaSzSux/WmMsR4LPTw8TIMGDUxYWJjJmDGjcXFxMQsXLoxT/u233zaSTOnSpU1YWJixWCymaNGi5s6dO3HKduvWzXh7e5t///3XadsIAAAApGc3b940+/btMzdv3nS4vL1ZUZoM237++WfzwQcfmAULFsQbtn3yySfGx8fHLFiwwOzZs8c0bdrUBAYG2hUoxUoPYdvOnTuNJJM9e/Z451+7ds1IMpkzZ06ynhs3bpjg4GBTr14967RmzZoZHx8fm/c1NDTU5MmT5yG3AvdLbJ/evHnTuLu7G0nmxIkTceavX7/eSDKhoaHWaXPnzjWSzIoVK2zWI8l07NjROm3mzJlGklm1apXzNgaEp2kc4SkAAACQtqVE2JYmbyOtXbu2PvroIzVq1CjOPGOMxo0bpw8++ECNGjVSsWLFNH36dN24cUOzZs1KgdamnCJFisjd3V3nzp3Tv//+G2f+jh07JEnFixdPcl3Dhw/XmTNnNG7cOOu0/fv3KyQkRD4+PtZpZcqU0b///qsrV644vgGIw9ERZmMxwmzqEBUVpbVr10qSGjduHGd+7LQlS5ZYp8XeIpwlSxbrtNj/v3jxonXarFmzFB4ervHjx8vV1dX5jX9C9O3bV0OGDFHdunWVM2fOJMuPHj1akjRgwAAVKlTIOr18+fLq0KGDIiMjNXXqVOv0vXv36s6dO2rVqpX1lv+2bdtKknbt2mWz7i5duuipp57Su+++6+hmAQAAAEhGaTJsS8yRI0d0+vRp1apVyzrN3d1doaGhCT4vR5Kio6N15coVm1da5+HhoerVq0uSfvjhhzjzY6fVrVs30fUcPnxYI0eOVJ8+fVSgQAGbeQ8Om3v9+nVJiT8nDo+OEWbTF8LT9IXwFAAAAICUDsO22AfMP9gDIWfOnIk+fH7EiBHy8/OzvoKCgpK1nY9Lz549JUkfffSRzY/zzZs3a/LkyfL19VW7du0SXUf37t0VGBiofv362Ux/5plntG/fPu3cuVOSdPXqVS1ZskR58+a16e0G52GE2fSF8DR9ITwFAAAAUi97f98643dwugvbYj3Ys8oYk2hvq/79+ysyMtL6OnHiRHI38ZEsW7ZM5cqVs76ke8PY3j9t2bJl1vI1atRQ9+7ddeHCBZUsWVINGzZUnTp1VKVKFd2+fVtTp06Vv79/ovUtW7ZMY8eOlYeHh8283r17y2KxqFq1amrUqJGKFy+uEydO6P3330+ejQcjzKYzhKfpC+EpAAAAkPrE3hny4J15CYkt58gdJRkfeclUKiAgQNK9Hm6BgYHW6WfPnk30eTvu7u5yd3dP9vY56ty5c9qyZYvNNGOMzbRz587ZzB83bpxKliypCRMmaPXq1XJ1ddWLL76oAQMGqFKlSgnWFR0dre7duyssLEwNGzaMM7948eL68ccfNWDAAC1dulQBAQH65JNP9M477zi2kUhQbI/B2Nt14xN7YPD29raZXr58eZUvX95m2oIFC7R69WotXbpU7u7u2r59u5o3b66wsDB9/vnnCg8P18cff6wcOXKoW7duTt4aOBKeFihQQPPnz1dUVJSqV6+uV199VVL84Wm/fv107Ngx+fn5qUuXLho6dKhzhrOGDXvD08uXL+vatWvy8fGxhqctW7bUs88+ay3XsWNHm/B00KBBccLTTJkyccs+AAAAkAQXFxdlzpxZZ8+elXTvej2+62hjjG7cuKGzZ88qc+bMcnFxeeQ6LSaNd3WwWCxatGiRNQwyxihXrlx699131adPH0n3en7lyJFDn376qd1B0JUrV+Tn56fIyEj5+vratcxzvb97pG3Ao9s+slVKN8HpLBaL3N3dFRUVFWferl27VKpUKWXPnt16oLjf9evX5e3tbe09k5ibN2/q6aefVvHixbV48WJJUvPmzbV06VL9999/1mCvatWqOnz4cKrt7ZnaJbY/Fy9erAYNGqhUqVLWAUselCVLFl2+fFlXrlxJ8vbsBQsWqHHjxlq6dKlefvllbd++XS+88ILCwsLUoUMHhYeHa+zYsfr8888JTx9RYvtz5syZeuONN1SpUiVt2LAh3uVz586tkydP6uTJkzb/ILR58+Y44anFYlGtWrX0zz//6K+//pK7uzvhqYO2b9+u1atXa+vWrdqyZYtOnjyZ4P6833fffacJEyZo3759cnNzU7ly5TRgwABVqFAhTtmoqCj16tVLc+fO1c2bN/Xiiy9q/Pjx1tuC7xcZGakiRYqoWrVqmj17ttO2EwAAALaMMTp9+rQuX76cZNnMmTMrICAg3kDO3qwoTfZsu3btmv7++2/r30eOHNGuXbvk7++vvHnzqkePHho+fLgKFSqkQoUKafjw4fL09FTz5s1TsNWA4x4cYfbB29WSa4TZ8PBwXblyxe7gGfaJ7akU32jB0r3w9PLly8qcOXOSQdvNmzfVq1cv1atXTy+//LKkeyNjent7a968efLx8VGDBg20Y8cOjRw5krAtGdDzNPUbNmyYfvrpp4dapmfPntZHKdSqVUtRUVFavXq1Vq1apfnz5+uVV16xKd+9e3dNmTJFpUuXVvbs2bV06VIdPnxYu3fvjvOvowMHDtT169c1atQoh7cNAAAACbNYLAoMDFSOHDl0+/btBMu5uro61KMtVpr8p/Bt27apVKlSKlWqlKR7F8KlSpXSwIEDJUl9+vRRjx491KlTJz3//PP677//tGrVKh7ajzSPEWbTlwfD0wclV3j677//posRl1ObxxmeNmjQQGPGjFFoaKhGjhzp3A1Jx8qXL6+BAwdqyZIliQ6aFOuXX37R2LFjlTVrVv3555/68ccftWLFCq1fv14uLi568803bXoRnzp1SlOnTlXt2rW1bds2rVixQsOGDdO+ffu0aNEim3Xv3btXX3zxhT788EPlzp3b6dsKAACAuFxcXJQpU6YEX84I2qQ0GrZVrVpVxpg4r2+//VbSvVBg8ODBOnXqlKKiohQeHq5ixYqlbKMBJ2GE2fSD8DR9ITxN/fr27ashQ4aobt26iT7HNdbo0aMlSQMGDFChQoWs08uXL68OHTooMjJSU6dOtU7fu3ev7ty5o1atWlm/Y23btpV07zEA9+vSpYueeuopvfvuu45uFgAAAFKZNBm2AekJI8w+2QhP0w/C0/QlKipKa9eulSQ1btw4zvzYaUuWLLFOi+3lliVLFuu02P+/ePGiddqsWbMUHh6u8ePHOzTKFQAAAFKnND9AQnJhgIS0ITkHSDg+9NmkCznB/J2X9N6P/yVaZlTD3HqtVBabafN3XtL0rRf097loubpYVCqPp7pWya4Xgr0SXE/0nRjVnPi38vm76buW+eIts+bAFY1ae1Z/n49Wdu+MavWCvzpWzv7Q2/Uo8g7c81jqSU7Lli3TsGHDrH9v2bJFFotFZcqUsU778MMPrbcGSlKPHj30+eefy9PTUzVr1tStW7e0evVqxcTEaN68edaRRhOqr27dujYDxcTavXu3SpUqJR8fH1WvXl07d+7U0aNH9eWXXzJq8CNKbIAESVqzZo1q1qyprFmzavPmzdbeUJs3b1a1atXk7u6uI0eOJBqI161bV3/99Zf27dtnE4i3bNlSM2fO1Pbt21WqVCldvXpVzzzzjCwWi44dO+bcDX1COGNAmixZsliDtN9//13ly5fX+PHj1aVLF0n3voclSpTQJ598or59++ratWsqUqSIypcvH28oCwAAgNQrXQ+QAKQnr5XKEidIS67l3DNm0PruhRMtU6OIr2oUYSCER3Xu3Dlt2bLFZpoxxmbauXPnbOaPGzdOJUuW1IQJE7R69Wq5urrqxRdf1IABA1SpUqUE64qOjlb37t0VFhYWJ2iT7t2u+OOPP2rAgAFaunSpAgIC9MknnxC0PYQHw1Pp/3qexro/PI3tefr555+rZMmSccLTmTNn2tXzdNGiRfH2PJ01a5aqVatmDU9PnDihL7/80olbjFjHjx+XpDgD0cTy8vKyjvx89epV+fj4qGTJkgoMDNSYMWNUtWpVZc+eXX369JHFYlHt2rUlSUOHDtXly5c1ZsyYx7YtAAAAeLzo2ZYAeralDemhZxv+T3L2bKs4vmKyrRvx+63rbyndBId9++23evPNNxMtM23aNLVp0ybOchMmTFBERIRcXV1Vrlw5u8LTZ555RgULFtSKFSviLbNkyRINGDBAERERCggIUOfOndW3b9+H3i7ck1jPtlmzZqlFixaqWLGiNm7cGO/yefLk0X///aeTJ08qMDBQkjRz5ky1bNlS919edezYUV988YUOHDigZ599VoMGDdIHH3xgnX/z5k1lypSJ24EBAABSOXq2AQDSrfAqoY+lnvyS1lWuknihqdMUPnVanOVGe3pJzz1/b8KNm7r7/gcKT6K+b3Lllm7cTHD7fCX9zy+zVK78vQnLflb4sp+TWKtzhK5PqvXpS2xYllgAFt+/V7Zo0UIFChTQ/PnzFRUVperVq1tvBe/atavy5s2r9957T5I0Z84c9evXT8eOHZOfn5+6dOmioUOHKkMGHqkLAACQlhG2AQAAPCB2EJHYQSjiEztghbe3t8308uXLq3z58jbTFixYoNWrV2vp0qVyd3fX9u3b1bx5c4WFhenzzz9XeHi4Pv74Y+XIkUPdunVz8tYAAADgcSJsAwAAeEDevHklSf/++2+8869fv67Lly8rc+bMSY7ue/PmTfXq1Uv16tWzPt9v9OjR8vb21rx58+Tj46MGDRpox44dGjlyJGEbAABAGsd9CgAAAA8oUqSI3N3dde7cuXgDtx07dki6NxBJUoYPH64zZ85o3Lhx1mn79+9XSEiITVBXpkwZ/fvvv7py5YrjGwAAAIAUQ9gGAADwAA8PD1WvXl2S9MMPP8SZHzutbt26ia7n8OHDGjlypPr06aMCBQrYzIu9DTVW7C2rDJQAAACQthG2AQAAxKNnz56SpI8++kiHDh2yTt+8ebMmT54sX19ftWvXLtF1dO/eXYGBgerXr5/N9GeeeUb79u3Tzp07JUlXr17VkiVLlDdv3iRvSwUAAEDqRtgGAACeCMuWLVO5cuWsL0m6deuWzbRly5ZZy9eoUUPdu3fXhQsXVLJkSTVs2FB16tRRlSpVdPv2bU2dOlX+/v6J1rds2TKNHTtWHh4eNvN69+4ti8WiatWqqVGjRipevLhOnDih999/P3k2HgAAAI8NAyQAAIAnwrlz57RlyxabacYYm2nnzp2zmT9u3DiVLFlSEyZM0OrVq+Xq6qoXX3xRAwYMUKVKlRKsKzo6Wt27d1dYWJgaNmwYZ37x4sX1448/asCAAVq6dKkCAgL0ySef6J133nFsIwEAAJDiLMYYk9KNSI2uXLkiPz8/RUZGytfX165lnuv9XTK3Cg/aPrJVsq37+NBnk23diF/egXuSbd0Vx1dMtnUjfr91/S3Z1h1eJTTZ1o34ha4PT9b1T+i1JFnXj7i6jK6X0k0AAABIU+zNiriNFAAAAAAAAHASwjYAAAAAAADASQjbAAAAAAAAACchbAMAAAAAAACchLANAAAAAAAAcBLCNgAAAAAAAMBJCNsAAAAAAAAAJyFsAwAAAAAAAJyEsA0AAAAAAABwEsI2AAAAAAAAwEkI2wAAAAAAAAAnIWwDAAAAAAAAnISwDQAAAAAAAHASwjYAAAAAAADASQjbAAAAAAAAACchbAMAAAAAAACchLANAAAAAAAAcBLCNgAAAAAAAMBJCNsAAAAAAAAAJyFsAwAAAAAAAJyEsA0AAAAAAABwEsI2AAAAAAAAwEkI2wAAAAAAAAAnIWwDAAAAAAAAnISwDQAAAAAAAHASwjYAAAAAAADASQjbAAAAAAAAACchbAMAAAAAAACchLANAAAAAAAAcBLCNgAAAAAAAMBJCNsAAAAAAAAAJyFsAwAAAAAAAJyEsA0AAAAAAABwEsI2AAAAAAAAwEkI2wAAAAAAAAAnIWwDAAAAAAAAnISwDQAAAAAAAHASwjYAAAAAAADASQjbAAAAAAAAACchbAMAAAAAAACchLANAAAAAAAAcBLCNgAAAAAAAMBJCNsAAAAAAAAAJyFsAwAAAAAAAJyEsA0AAAAAAABwEsI2AAAAAAAAwEkI2wAAAAAAAAAnIWwDAAAAAAAAnISwDQAAAAAAAHASwjYAAAAAAADASZI9bFuyZIlatmyp2rVrq1OnTtq5c2dyV6k7d+5owIAByp8/vzw8PFSgQAENHTpUMTExyV43AAAAAAAAnlwOhW2//vqrcuTIobx58+ry5ctx5n/44Ydq2LChZs2apVWrVmny5MkqW7asZs6c6Ui1Sfr000/15ZdfasKECYqIiNBnn32mkSNHavz48claLwAAAFKH33//Xa+++qoCAgLk6uoqf39/vfjii/rhhx/ilD169Kjq1q0rT09PZc+eXV27dlVUVFS86928ebMyZMigyZMnJ/cmAACANMqhsO3nn3/W+fPnVa5cOWXOnNlm3u7duzV8+HAZY2SMUebMmWWM0Z07d/T222/r2LFjjlSdqM2bN6tBgwZ6+eWXlS9fPjVu3Fi1atXStm3bkq1OAAAApA7z589XxYoVtXDhQgUFBenVV19VsWLFtG7dOr322mvq16+ftezdu3dVp04d/fzzzwoNDVVQUJAmTJigd999N856Y2Ji1KVLF5UuXVrt27d/nJsEAADSEIfCto0bN8pisahmzZpx5k2aNEnGGGXJkkXbt2/XhQsXtHXrVvn7+ysqKkpffvmlI1UnqlKlSlq7dq0OHjwoSfrzzz+1ceNG1alTJ8FloqOjdeXKFZsXAAAA0pY7d+6oc+fOiomJ0Zw5c/THH39ozpw5Wr9+vTZu3KhMmTLps88+0+HDhyVJixYtUkREhIYPH67ly5dr27ZtqlWrlr7++mudOnXKZt2TJ0/Wzp07NXHiRGXIwKOPAQBA/By6Sjh9+rQkKSQkJM68pUuXymKxqHPnzipVqpQk6fnnn1eXLl1kjNGaNWscqTpRffv2VbNmzRQSEiJXV1eVKlVKPXr0ULNmzRJcZsSIEfLz87O+goKCkq19AAAASB779+/XuXPnFBISoqZNm9rMK1++vMLCwmSM0fbt2yXJ+jzhNm3aSJIyZMigNm3a6M6dO/rrr7+sy164cEEDBgzQm2++qbJlyz6ejQEAAGmSQ2Hb2bNnJUl+fn420w8fPqz//vtPktSoUSObeZUrV5Yk/f33345Unai5c+dqxowZmjVrlnbs2KHp06dr1KhRmj59eoLL9O/fX5GRkdbXiRMnkq19AAAASB7u7u52lfP395ckXbp0SZKUJUsW67zY/7948aJ1Wv/+/RUTE6NPPvnEWU3FQ+I5fACAtCKjIwsbYyRJkZGRNtM3bNgg6V4IV7JkSZt5WbNmlSTduHHDkaoT1bt3b/Xr10+vv/66JOnZZ5/VsWPHNGLECLVu3TreZdzd3e2+OAMAAEDqVKBAARUoUED79+/XvHnz1KRJE+u8zZs3a+XKlcqfP7+qVKkiScqbN68k6dChQypWrJgkWR9FEhwcLEnavn27vvnmG33++efKnj3749wc/H/z58/X66+/rpiYGD3//POqWrWqTp48qXXr1umXX35R3759rUFo7HP49u/fr7CwMJ05c0YTJkzQnTt3NGnSJJv18hw+AEBycKhnW0BAgCQpIiLCZvrKlSslSRUrVoyzzPXr1yXZ/uuhs924cSPOczRcXFwUExOTbHUCAAAg5bm4uOjbb7+Vn5+fmjZtqhdeeEGvv/66QkNDValSJZUsWVKrVq2Sm5ubJKl27dqyWCzq27evzp49qz179mjMmDHKnTu3SpQoIWOMOnfurGLFiqljx44pvHVPJp7Dl76sW7dOFoslydfQoUOty9BTEUBa49AZpVy5cjLGaNKkSdaeav/8849++umnBAdOiP2XwtigLjnUq1dPH3/8sZYtW6ajR49q0aJFGjNmjF555ZVkqxMAAACpQ+XKlRUeHq78+fNr27Ztmjt3rtavXy8vLy/VqFFDuXLlspYtUaKE3nrrLf3888/KmTOnihcvruPHj2v06NHKlCmTpk2bpi1btmjChAlycXGxLnfz5s2U2LQnEs/hS18CAgLUunXreF9vvPGGtVzs44cYMTh1IzwF4ufQbaRvvfWW5syZo927d6tYsWIqXbq01q9fr6ioKHl6eqp58+Zxllm/fr0kqWjRoo5Unajx48frww8/VKdOnXT27FnlypVL77zzjgYOHJhsdQIAACB1mD17tt58802VK1dOc+bM0TPPPKOTJ09q1KhR+uijj7R27VqFh4fL1dVV0r3eTTVq1NC6devk4eGhpk2bqkyZMrp8+bL69eunN954Q5UrV1ZMTIw+/PBDTZw4UZGRkQoODtZnn31mc6sqnI/n8KUvISEh+vbbb+Odt3z5cs2YMUNBQUEKDQ2V9H89FUeMGKF+/fopJiZGtWvX1tdff62BAwcqMDDQunxsT8XYgAbJLzY8jc/du3c1Y8YMSXHDU27zRnrnUNhWvXp19ejRQ+PGjdPRo0d17Ngx63PcRo4cqWzZstmUj4qKSrTXm7P4+Pho3LhxGjduXLLVAQAAgNTn0KFDat26tXLmzKlly5bJy8tLklSoUCFNnjxZp06d0pIlSzRt2jS9/fbbkiSLxaImTZrECc0+/PBDRUdHa+TIkZKkcePGafjw4erRo4eqVaumL7/8Us2aNVPhwoXjPKcYzsNz+J4cscFMixYtrGFZQj0VV61apb/++ssattFTMWUQngLxc/gTO2bMGC1evFgtW7ZUjRo11KpVK61ZsybeZ1osXrxYvr6+yps3b7KGbQAAAHgyzZkzR7dv39ZLL71kDdruFxvUrFu3LtH17N69W5MmTdKgQYOsjz8ZNWqUqlatqrFjx6p+/fqaO3euvLy8NHr0aKdvB/4Pz+F7Mly/fl0//fSTJNncTkpPxbTrYcJTbvNGeuNQz7ZYdevWVd26dZMsF9+/GAIAAADO8u+//0qSfH19450fO/3+H+nx6dKli4oUKaJu3bpJkq5cuaJTp07ZhAA+Pj4KCQnRvn37nNF0JCL2OXyvvPKKtm3bpm3btkm6tw8Seg7fV199pZw5c0q613tx9uzZypQpk6ZOnaotW7Zo/fr1cZ7D5+Hh8Xg3DFYLFy7U9evXVapUKT3zzDPW6fRUTJsIT/Gkc6hn29ChQzV06FDr6KMAAABASorthRYbxjzojz/+kCTly5cvwXXMmDFDGzZs0IQJE5Qxo+2/TccOChbr+vXrslgsDrQY9pg9e7bKli2rvHnzasuWLbp27ZoOHjyoZs2a6aOPPlKNGjV0+/Zta/nJkydr7ty56tixo3r27Knff/9dTZs2jfc5fB988IEyZ84sT09P5cuXT/PmzUvBLX1yxfaCatmypc10eiqmTfaEp7ESCk+HDRtGeIo0y6GwbfDgwRoyZIiio6Od1R4AAADgkTVo0EDSvUG5HnzY9u+//66xY8dKkho3bhzv8levXlWfPn3UtGlTVatWzTrd19dXefLk0eLFi3X16lVJ926HioiIsPkhCeeLfQ5f9uzZtWzZMpUpU0ZeXl7W5/DVq1dPmzdv1rRp06zLxD6H74svvtDo0aNVpkwZSQk/h+/NN9/UTz/9pKJFi6pZs2batWtXSmzqE+v06dNau3atXFxc1KxZM5t5jBicNhGe4knnUNiWNWtWSf+XTgMAAAApqXTp0nrvvfckSZ06dVKxYsXUpEkTVapUSRUrVtT169f19ttvq0aNGvEuP2TIEF25ckWjRo2KM69fv346ceKEihcvrkaNGqlatWrKkCGD+vTpk6zb9KTjOXzp36xZs3T37l3VrFnTum/uR0/FtIXwFHAwbCtYsKCke18mAAAAIDUYOXKkFi5cqFq1aun06dNatGiR9u3bp9DQUM2cOVOTJ0+Od7mIiAj973//04ABA5QnT5448zt16qQRI0bo7t27Wrp0qfLmzauffvqJnm3JLLmfw/fCCy9Yy/AcvpSRUC+oWPRUTFsITwEHB0ho2rSptmzZonnz5umll15yVpsAAACQhn38Rvy3aD5uVbL7qMpLVW2mHfl5oT7+eWGCywxqUl93925LdBveqVLG+v+7Zk/TrtnTEiz7uHww44eUbkKyceZz+H755Re7nsPHQAmPT0REhHbu3Clvb281bNjQ7uVieyp+9tln8fZUlKRq1aopd+7cGj16tL7//vvkaD7iYW94+uDgiQmFpz169FC1atX05ZdfqlmzZipcuLBKliyZrNsAOMqhnm2dOnVSiRIl9N1332n69OnOahMAAAAASOI5fOldbAjWqFEjeXp62r0cPRVTJ0fDU27zRnrhUM+206dP6+uvv1a7du3Utm1bzZw5U82bN1fx4sWVJUsWm3us48Oz3gAAAAAkJvY5fKNGjVKnTp00ceJEFS1aVCdPntTmzZsVExPj0HP4unTpouLFi6tUqVL65ZdfeA7fY2SM0axZsyQl3AsqPvRUTL2cHZ6+8cYb1jKEp0hLHArb8uXLZx3q3BijtWvXau3atXYta7FYdOfOHUeqBwAAAPAEGDlypCpUqKAvv/xS27dv14EDB+Tj46PQ0FC99dZbat68ebzLxT6Hb+jQoQk+h+/q1av64osvtHTpUoWEhGjEiBH0bHtMNmzYoGPHjilXrlyqXr26XcvY01NxxIgR8vHxsfZUfJggD4+O8BT4Pw6FbdK9L1R8/w8AAAAg7Yv4+JeUboIkKUR+Glelr1TlgRlHEm/jn4NWSHcTLtNAZdTgnf97Dp92SRG7Unabn/7AvuAprYt9tleLFi2UIYN9Tziip2LqRXgK/B+HwrZp01L+YbAAAAAAgLQlOjpaP/xwb2CP+28VTAw9FVM3wlPg/zgUtrVu3dpZ7QAAAAAAJLPBgwendBOsYp/PtXDhQi1cmPAowfd7//33FRUVleh2tG3b1vr/f/zxh3XE2pSSmt7z5EJ4Cthy+DZSAAAAAACQMubNL5N0ocfgy8kFJUn7D7yl/QfsW2bGzJKSFmre/PjD1gJPSaNGB0i6N0Lp9RtDNG/+EMcb66Amr21N6SYglbOvbycAAAAAAACAJDmtZ1tMTIzWrVunzZs36/Tp07px44Y++ugjBQYGWsvcunVLd+7ckYuLi9zd3Z1VNQAAAAAAAJAqOCVsW7Zsmbp166ajR4/aTO/Vq5dN2PbNN9+oS5cu8vb21smTJ+Xl5eWM6gEAAAAAAIBUweHbSL/++mvVr19fR44ckTFGWbNmlTEm3rLt2rVT5syZde3aNS1atMjRqgEAAAAAAIBUxaGw7e+//1bnzp0lSdWrV9e+fft09uzZBMu7ubnp1VdflTFGq1atcqRqAAAAAAAAINVxKGwbN26cbt++rWeeeUY///yzQkJCklymcuXKkqRdu3Y5UjUAAAAAAACQ6jgUtq1du1YWi0U9evSQm5ubXcs89dRTkqTjx487UjUAAAAAAACQ6jgUtp04cUKSVLJkSbuXiR0U4caNG45UDQAAAAAAAKQ6DoVtFotFkhIcECE+586dkyT5+vo6UjUAAAAAAACQ6jgUtuXKlUuSdPDgQbuXCQ8PlyTly5fPkaoBAAAAAACAVMehsK1KlSoyxmjWrFl2lT9//rwmT54si8Wi6tWrO1I1AAAAAAAAkOo4FLa9/fbbkqSff/5Z06ZNS7Tsv//+qzp16uj8+fNycXGxLgsAAAAAAACkFw6FbS+88II6dOggY4zeeustvfbaa5o3b551/u7duzV37ly1a9dORYoU0fbt22WxWNSrVy8VLFjQ4cYDAAAAAAAAqUlGR1cwfvx4Xb9+Xd9//70WLlyohQsXWgdOaNGihbVc7CAKbdq00fDhwx2tFgAAAAAAAEh1HOrZJkkuLi6aPn265s+fr1KlSskYE++raNGimjVrlqZOnWoN4wAAAAAAAJA6rFu3ThaLJcnX0KFDrcscPXpUdevWlaenp7Jnz66uXbsqKioq3vVv3rxZGTJk0OTJkx/XJqUIh3u2xXr11Vf16quv6uTJk9q2bZvOnj2ru3fvKmvWrCpVqpSeeuopZ1UFAAAAAAAAJwsICFDr1q3jnXf37l3NmDFDklS5cmXrtDp16mj//v0KCwvTmTNnNGHCBN25c0eTJk2yWT4mJkZdunRR6dKl1b59++TdkBTmtLAtVq5cuVS/fn1nrxYAAAAAAADJKCQkRN9++22885YvX64ZM2YoKChIoaGhkqRFixYpIiJCI0aMUL9+/RQTE6PatWvr66+/1sCBAxUYGGhdfvLkydq5c6e1d1t6lr63DgAAAAAAAA6L7dXWokULa1i2c+dOSfeezy9JGTJkUJs2bXTnzh399ddf1mUvXLigAQMG6M0331TZsmUfb8NTAGEbAAAAAAAAEnT9+nX99NNPkqQ33njDOv3SpUuSpCxZslinxf7/xYsXrdP69++vmJgYffLJJ4+juSnOabeR/vnnn9qwYYP++ecfXb16VXfv3k20vMVi0TfffOOs6gEAAAAAAJAMFi5cqOvXr6tUqVJ65plnrNPz5s0rSTp06JCKFSsmSTp48KAkKTg4WJK0fft2ffPNN/r888+VPXv2x9zylOFw2BYREaF27dppy5Ytdi9jjCFsAwAAAAAASANibyFt2bKlzfTatWvr/fffV9++fTVt2jSdOXNGY8aMUe7cuVWiRAkZY9S5c2cVK1ZMHTt2TImmpwiHwrZ//vlHlSpV0uXLl2WMkST5+Pgoc+bM6f5hdwAAAAAAAOnd6dOntXbtWrm4uKhZs2Y280qUKKG33npLX331lXLmzCnp3p2Ms2fPVqZMmTR16lRt2bJF69evl4uLi3W5mzdvysPD47Fux+PkUNg2cOBAXbp0SRkyZNB7772njh07Kl++fE5qGgAAAAAAAFLSrFmzdPfuXb300ksKCAiIM3/y5MmqUaOG1q1bJw8PDzVt2lRlypTR5cuX1a9fP73xxhuqXLmyYmJi9OGHH2rixImKjIxUcHCwPvvsMzVp0iQFtip5ORS2rVmzRhaLRT169NCnn37qrDYBAAAAAAAgFUjoFtJYFotFTZo0iROaffjhh4qOjtbIkSMlSePGjdPw4cPVo0cPVatWTV9++aWaNWumwoULq2TJksm6DY+bQ/d6XrlyRZL06quvOqUxAAAAAAAASB0iIiK0c+dOeXt7q2HDhnYvt3v3bk2aNEmDBg2y9oYbNWqUqlatqrFjx6p+/fqaO3euvLy8NHr06GRqfcpxKGwLCgqSJGXM6LRBTQEAAAAAAJAKfP/995KkRo0aydPT0+7lunTpoiJFiqhbt26S7nXWOnXqlF544QVrGR8fH4WEhGjfvn3ObXQq4FDYFhYWJknaunWrUxoDAAAAAACAlGeM0axZsyQlfAtpfGbMmKENGzZowoQJcTpn3bhxw+bv69evy2KxON7YVMahsK1Xr17y8fHRyJEjdfHiRWe1CQAAAAAAAClow4YNOnbsmHLlyqXq1avbtczVq1fVp08fNW3aVNWqVbNO9/X1VZ48ebR48WJdvXpVkrRz505FRETomWeeSZb2pySHwrbg4GAtXLhQly5dUoUKFbRmzRpntQsAAAAAAAApJHZghBYtWihDBvvioyFDhujKlSsaNWpUnHn9+vXTiRMnVLx4cTVq1EjVqlVThgwZ1KdPH6e2OzVw+GFr1atX144dO1ShQgWFhYUpS5YsKliwYJL38losFq1du9bR6gEAAAAAAOBE0dHR+uGHHyRJb7zxhl3LRERE6H//+5+GDh2qPHnyxJnfqVMnXb16VV988YWWLl2qkJAQjRgxIl32bHM4bNu0aZNatmyp8+fPyxijixcvJvoMN4vFImNMurwnFwAAAAAA4FGV+GFlSjfBKmjKbAVJannwlHTwlF3LPD1riWZLmp3QdhQspSxjvlKW///n+zel91N4m/9sHOb0dToUtu3bt0+1atXSzZs3ZYxRpkyZVKhQIWXOnNnuLoYAAAAAAABAeuFQ2DZkyBDduHFD7u7uGjNmjN58801lypTJWW0DAAAAAAAA0hSHwrbffvtNFotF77//vjp27OisNgEAAAAAAABpkkP3el66dEmS9NJLLzmlMQAAAAAAAEBa5lDYFju6xN27d53SGAAAAAAAACAtcyhsq1evniRp/fr1TmkMAAAAAAAAkJY5FLb17t1bOXLk0MiRI3X06FEnNQkAAAAAAABImxwK23LmzKmVK1fK19dXZcuW1VdffaXLly87qWkAAAAAAABA2uLQaKQFChSQJN24cUPnzp1Thw4d1LFjR2XLlk2enp6JLmuxWHT48GFHqgcAAAAAAABSFYfCtgdvHTXGyBijs2fPJrmsxWJxpGoAAAAAAAAg1XEobGvdurWz2gEAAAAAAACkeQ6FbdOmTXNWOwAAAAAAAIA0z6EBEgAAAAAAAAD8H8I2AAAAAAAAwEkcuo00PmfOnNHevXt18eJFSZK/v7+KFSumnDlzOrsqAAAAAAAAIFVxSthmjNGUKVM0YcIE7du3L94yRYsWVdeuXdW+fXtGIgUAAAAAAEC65PBtpJcuXVLlypXVqVMn7du3T8aYeF/79u1Tx44dVaVKFV2+fNkJTQcAAAAAAABSF4d6thlj1KBBA23atEmSlDVrVjVp0kRly5ZVQECAjDE6c+aMtm7dqnnz5un8+fPatGmTGjRooPDwcKdsAAAAAAAAAJBaONSzbdasWdq4caMsFotatGihf/75RxMnTlSrVq1Uq1YthYWFqVWrVpowYYL++ecftWzZUsYYbdy4UbNnz3bWNsTrv//+0xtvvKGsWbPK09NTJUuW1Pbt25O1TgAAAAAAADzZHA7bJCk0NFTff/+9fHx8Eizr7e2t6dOnKzQ0VMYYzZgxw5GqE3Xp0iVVrFhRrq6uWr58ufbt26fRo0crc+bMyVYnAAAAAAAA4NBtpDt27JDFYlGXLl3sXqZr164KDw/Xzp07Hak6UZ9++qmCgoI0bdo067R8+fIlW30AAAAAAACA5GDPtosXL0qS8ufPb/cysWVjl00Oixcv1vPPP6/XXntNOXLkUKlSpfTVV18lukx0dLSuXLli8wIAAAAAAAAehkNhm5+fnyTp5MmTdi8TW9bX19eRqhP1zz//aNKkSSpUqJBWrlypDh06qFu3bvruu+8SXGbEiBHy8/OzvoKCgpKtfQAAAAAAAEifHArbihUrJkk2t2smZerUqTbLJoeYmBiVLl1aw4cPV6lSpfTOO++offv2mjRpUoLL9O/fX5GRkdbXiRMnkq19AAAAAAAASJ8cCtsaN24sY4wWLVqkwYMHyxiTYFljjAYPHqxFixbJYrHotddec6TqRAUGBqpo0aI2055++mkdP348wWXc3d3l6+tr8wIAAAAAAAAehkMDJLRv314TJkzQ/v37NWzYMC1YsEBt2rRR2bJllTNnTlksFp0+fVpbtmzR9OnT9ddff0mSQkJC1L59e6dsQHwqVqyoAwcO2Ew7ePCggoODk61OAAAAAAAAwKGwzdXVVcuXL1f16tV15MgR7du3T3369EmwvDFGBQoU0PLly5Uxo0NVJ+rdd99VhQoVNHz4cDVp0kRbt27VlClTNGXKlGSrEwAAAAAAAHDoNlJJCg4O1u7du9WrVy/5+fnJGBPvy8/PT++995527dqlvHnzOqPtCXrhhRe0aNEizZ49W8WKFdOwYcM0btw4tWjRIlnrBQAAAAAAwJPNKd3LvLy8NHLkSH388cfavn279u7dq4sXL0qS/P39VaxYMT333HNyc3NzRnV2qVu3rurWrfvY6gMAAAAAAACcei+nm5ubypcvr/LlyztztQAAAAAAAECa4FDY9t1330mSGjZsaPfondeuXdPChQslSa1atXKkegAAAAAAACBVcShsa9OmjSwWi55//nkVLVrUrmXOnDmjNm3aKEOGDIRtAAAAAAAASFccHiDhURljUqpqAAAAAAAAIFk89rDtzp07kqSMGZ36uDgAAAAAAAAgxT32sO3AgQOS7o1SCgAAAAAAAKQnD9W9bP369fFO/+OPP3T+/PlEl42Ojtbhw4c1atQoWSwWlSxZ8mGqBgAAAAAAAFK9hwrbqlatKovFYjPNGKO2bdvavQ5jjCwWi955552HqRoAAAAAAABI9R76NlJjjPUV37SkXnny5NHEiRPVsGFDZ24HAAAAAAAAkOIeqmfbr7/+av1/Y4yqV68ui8Wib775Rvnz509wOYvFokyZMikwMFBBQUGP3loAAAAAAAAgFXuosC00NDTe6WXKlFHRokWd0iAAAAAAAAAgrXqosO1BR44ckSTlzp3bKY0BAAAAAAAA0jKHwrbg4GBntQMAAAAAAABI8xwK2+yxZMkSzZs3T+fPn1f+/PnVvn17lSpVKrmrBQAAAAAAAB67hx6N9H6//vqrcuTIobx58+ry5ctx5n/44Ydq2LChZs2apVWrVmny5MkqW7asZs6c6Ui1AAAAAAAAQKrkUNj2888/6/z58ypXrpwyZ85sM2/37t0aPny4jDEyxihz5swyxujOnTt6++23dezYMUeqBgAAAAAAAFIdh8K2jRs3ymKxqGbNmnHmTZo0ScYYZcmSRdu3b9eFCxe0detW+fv7KyoqSl9++aUjVQMAAAAAAACpjkNh2+nTpyVJISEhceYtXbpUFotFnTt3tj6j7fnnn1eXLl1kjNGaNWscqRoAAAAAAABIdRwK286ePStJ8vPzs5l++PBh/ffff5KkRo0a2cyrXLmyJOnvv/92pGoAAAAAAAAg1XEobDPGSJIiIyNtpm/YsEHSvRCuZMmSNvOyZs0qSbpx44YjVQMAAAAAAACpjkNhW0BAgCQpIiLCZvrKlSslSRUrVoyzzPXr1yVJWbJkcaRqAAAAAAAAINVxKGwrV66cjDGaNGmStafaP//8o59++inBgRMOHjwo6f+COgAAAAAAACC9cChse+uttyRJu3fvVrFixdS4cWOVK1dOUVFR8vDwUPPmzeMss379eklS0aJFHakaAAAAAAAASHUcCtuqV6+uHj16yBijo0ePatGiRTp//rwkaeTIkcqWLZtN+aioqER7vQEAAAAAAABpWUZHVzBmzBhVr15d8+fP1+nTpxUYGKhWrVqpevXqccouXrxYvr6+8vPzI2wDAAAAAABAuuNw2CZJdevWVd26dZMs16RJEzVp0sQZVQIAAAAAAACpjkO3kQIAAAAAAAD4P4RtAAAAAAAAgJM4dBvp8ePHHao8b968Di0PAAAAAAAApCYOhW358+d/5GUtFovu3LnjSPUAAAAAAABAquJQ2GaMcVY7AAAAAAAAgDTPobBt2rRpSZa5fv26Dhw4oAULFujkyZOqUKGC2rdv70i1AAAAAAAAQKrkUNjWunVru8uOGjVK3bp105QpU1ShQgV99tlnjlQNAAAAAAAApDqPbTRSV1dXTZo0SVWqVNHo0aO1cuXKx1U1AAAAAAAA8Fg8trAtVseOHWWM0fjx4x931QAAAAAAAECyeuxhW6FChSRJ27Zte9xVAwAAAAAAAMnqsYdtkZGRNv8FAAAAAAAA0ovHHrZNnz5dkhQYGPi4qwYAAAAAAACS1WML2w4dOqQOHTpo+vTpslgsqlOnzuOqGgAAAAAAAHgsMjqycIECBZIsExMTo8uXL+vq1avWaTly5NAHH3zgSNUAAAAAAABAquNQ2Hb06NGHXqZcuXKaNm0at5ECAAAAAAAg3XEobGvdunWSZTJkyCAfHx/lz59foaGhKlmypCNVAgAAAAAAAKmWQ2HbtGnTnNUOAAAAAAAAIM177KORAgAAAAAAAOkVYRsAAAAAAADgJA91G+l///2nBQsWSJKKFy+uqlWr2r3sr7/+qj179kiSmjRpooCAgIepGgAAAAAAAEj1Hips69Wrl+bPn68cOXJo+/btD1VR4cKF1axZM507d047duzQt99++1DLAwAAAAAAAKmd3beRHj16VPPnz5ckffbZZ8qVK9dDVZQ7d26NHj1axhjNmDFDJ06ceLiWAgAAAAAAAKmc3WHbzJkzZYxRoUKF1LJly0eqrEWLFgoJCZExRjNnznykdQAAAAAAAACpld1h24YNG2SxWNSoUSOHKnz11VdljFF4eLhD6wEAAAAAAABSG7vDtr1790qSKlas6FCF5cqVs1kfAAAAAAAAkF7YHbZdvHhRkhweRTR2+dj1AQAAAAAAAOmF3WGbi4uLJOn27dsOVRi7vMVicWg9AAAAAAAAQGpjd9iWPXt2SdK///7rUIWxy8euDwAAAAAAAEgv7A7bChUqJEn65ZdfHKowdvnChQs7tB4AAAAAAAAgtbE7bKtZs6aMMZo1a5bOnz//SJWdP39eM2fOlMViUY0aNR5pHQAAAAAAAEBqZXfY9vrrr8vd3V1Xr15V27ZtFRMT81AVGWPUrl07Xb16VW5ubmrWrNlDNxYAAAAAAABIzewO2/LkyaNOnTrJGKNly5apTp06OnXqlF3Lnjp1Si+//LKWLFkii8Wijh07Kk+ePI/caAAAAAAAACA1yvgwhUeMGKHff/9dmzdv1urVq1WwYEE1btxYdevWVenSpZUzZ055eXnp+vXrOnPmjHbs2KFly5Zp/vz5ioqKkiSVLVtWn3zySbJsDAAAAAAAAJCSHipsc3Nz05IlS9S0aVOtXbtWN2/e1IwZMzRjxoxElzPGSJKqVaumefPmyc3N7dFbDAAAAAAAAKRSdt9GGsvf31+rVq3S2LFjlTt3bhljknzlypVLY8aM0Zo1a5Q1a9bk2A4AAAAAAAAgxT1Uz7ZYFotF3bt3V+fOnbVy5UqFh4frzz//1Pnz53X16lX5+PgoW7ZsKlGihEJDQ1WrVi25uro6u+0AAAAAAABAqvJIYZt14YwZ9fLLL+vll192VnsAAAAAAACANOuhbyNNi0aMGCGLxaIePXqkdFMAAAAAAACQjqX7sO2PP/7QlClTVLx48ZRuCgAAAAAAANK5dB22Xbt2TS1atNBXX32lLFmypHRzAAAAAAAAkM6l67Ctc+fOevnll1WjRo0ky0ZHR+vKlSs2LwAAAAAAAOBhODRAQmo2Z84c7dixQ3/88Ydd5UeMGKEhQ4Ykc6sAAAAAAACQnqXLnm0nTpxQ9+7dNWPGDGXKlMmuZfr376/IyEjr68SJE8ncSgAAAAAAAKQ36bJn2/bt23X27Fk999xz1ml3797V+vXrNWHCBEVHR8vFxcVmGXd3d7m7uz/upgIAAAAAACAdSZdh24svvqg9e/bYTHvzzTcVEhKivn37xgnaAAAAAAAAAGewK2xbvHixpHshlpeXV7I2yBl8fHxUrFgxm2leXl7KmjVrnOkAAAAAAACAs9j1zLaGDRuqUaNGOnbsmM30tm3bql27djp16lSyNA4AAAAAAABIS+y+jdQYE2fat99+K4vFol69eikwMNCpDXO2devWpXQTAAAAAAAAkM7Z1bMtduCAa9euJWtjAAAAAAAAgLTMrrAtd+7ckqQNGzYka2MAAAAAAACAtMyu20hffPFFffXVV3r//fe1detWFS5cWK6urtb5X3zxhXLkyPHQlQ8cOPChlwEAAAAAAABSK7vCtgEDBmjhwoW6cOGCfvjhB5t5xhhNmjTpkSonbAMAAAAAAEB6YtdtpEFBQdqxY4feeust5cuXT66urjLGyGKxSLoXuD3KCwAAAAAAAEhP7B6NNCgoSFOmTLGZliFDBlksFu3Zs0dFixZ1euMAAAAAAACAtMSunm0AAAAAAAAAkmZ3z7b4TJs2TZKUJ08epzQGAAAAAAAASMscCttat27trHYAAAAAAAAAaZ5DYduDbt++rR07dmjv3r26ePGiJMnf31/FihVT6dKl5erq6szqAAAAAAAAgFTFKWHbjRs3NGzYMH311Ve6dOlSvGWyZMmit99+WwMGDJCnp6czqgUAAAAAAABSFYcHSDh+/LhKliypzz77TBcvXpQxJt7XxYsX9emnn6pUqVL6999/ndF2AAAAAAAAIFVxqGfb7du3Vbt2bf3999+SpJCQEL355psqW7asAgICZIzRmTNntHXrVn377bfat2+fDh06pNq1a2vnzp3KmNGpd7ECAAAAAAAAKcqhnm1ff/21IiIiZLFY9MEHH2jv3r3q3bu3qlSposKFC6tIkSKqUqWK3nvvPe3evVsDBgyQJO3bt09ff/21UzYAAAAAAAAASC0cCtvmz58vi8Wihg0batiwYcqQIeHVZciQQUOHDtUrr7wiY4zmz5/vSNUAAAAAAABAquNQ2LZ3715JUtu2be1epl27dpKkPXv2OFI1AAAAAAAAkOo4FLZFRkZKknLlymX3MoGBgZKkK1euOFI1AAAAAAAAkOo4FLb5+/tLko4cOWL3Mv/884/NsgAAAAAAAEB64VDYVrp0aRljNHHiRLuXmThxoiwWi0qVKuVI1QAAAAAAAECq41DY1qxZM0nSunXr1LZtW12/fj3BstevX1fbtm21bt06SVKLFi0cqRoAAAAAAABIdTI6snCLFi305ZdfatOmTZo+fbqWLVumJk2aqGzZssqZM6csFotOnz6tLVu2aP78+Tp37pwkqWLFimrevLlTNgAAAAAAAABILRwK2ywWi5YsWaKXX35Zv//+u86dO6cvvvhCX3zxRZyyxhhJUvny5fXTTz85Ui0AAAAAAACQKjl0G6kkZcmSRRs3btT48eP19NNPyxgT7+vpp5/WhAkTtGHDBmXJksUZbQcAAAAAAABSFYd6tsXKkCGDOnfurM6dO+vUqVPau3evLl68KOneqKPFihVTYGCgM6oCAAAAAAAAUi2nhG33CwwMJFgDAAAAAADAE8nh20gBAAAAAAAA3EPYBgAAAAAAADgJYRsAAAAAAADgJIRtAAAAAAAAgJMQtgEAAAAAAABOQtgGAAAAAAAAOAlhGwAAAAAAAOAkhG0AAAAAAACAkxC2AQAAAAAAAE5C2AYAAAAAAAA4ScbkWvGxY8c0c+ZM7dq1S5GRkfL19VXJkiXVvHlz5c+fP7mqBQAAAAAAAFJMsoRtY8aM0fvvv6/bt2/LGGOdvnDhQg0dOlQff/yx3nvvveSoGgAAAAAAAEgxTg/b5s2bp/fee08Wi0Uvv/yyKlasqMyZM+vEiROaO3euDh8+rL59+ypv3rxq0qSJs6sHAAAAAAAAUozTw7bRo0fLYrHohx9+0CuvvGIzb+jQoWrQoIGWLVumMWPGELYBAAAAAAAgXbF7gIRff/3VrnJ79+5V/vz54wRtkpQhQwb17NlTkrRnzx57qwYAAAAAAADSBLvDthdffFHNmzfXqVOnEi3n5uamK1euJDg/MjLSWg4AAAAAAABIT+wO24KDgzVnzhyFhIRo9OjRunv3brzlKlasqAsXLqhnz566deuWzbyjR4+qX79+slgsqlSpkmMtBwAAAAAAAFIZu8O2iIgIvf/++7p165b69OmjEiVKaN26dXHKDRkyRO7u7vr888+VN29evfzyy2revLmqVKmiwoUL6+DBg3J3d9eQIUOcuR0AAAAAAABAirM7bMuUKZM++ugj7d27V7Vq1dK+ffust5aePHnSWu65557T8uXLlT9/fp09e1bLly/XnDlztHHjRt25c0cFChTQihUrVLp06WTZIAAAAAAAACClPPRopE899ZSWL1+uhQsX6t1339WcOXO0dOlSDRo0SD169JCLi4tCQ0N16NAh/fbbb9q1a5ciIyPl5+enEiVKqFKlSrJYLMmxLQAAAAAAAECKeuiwLVajRo1Uu3ZtDRs2TGPGjFGfPn00bdo0jR8/XtWqVbM+l41nswEAAAAAAOBJYfdtpPHx8PDQ8OHDtXv3btWoUUP79u1TjRo11KxZM5tbSwEAAAAAAIAngUNhW6zChQtr5cqVmjdvnnLnzq25c+cqJCREo0aNSnDUUgAAAAAAACC9cUrYFqtx48bav3+/evfurejoaPXt21fFixfXr7/+6sxqAAAAAAAAgFTpocO2zZs365133lGZMmVUpEgRlSlTRu3bt9fGjRslSZ6envr000/1559/qlq1aoqIiODWUgAAAAAAADwRHips69WrlypVqqSvv/5a27Zt06FDh7Rt2zZNnTpVoaGh6tq1q7VsSEiI1qxZo9mzZyswMNDm1tI7d+44fUMAAAAAAACAlGZ32Pb1119r7NixMsaoZs2amjZtmpYvX65p06apZs2aMsboiy++0JQpU2yWa9q0qQ4cOKBevXpZby0tUaIEt5YCAAAAAAAg3bE7bJs0aZIsFovatm2rFStWqHXr1goLC1Pr1q21YsUKtWvXTsYYTZo0Kc6yXl5eGjlypHbt2qXQ0FBFRESoZs2aTt0QAAAAAAAAIKXZHbZFRERIktq0aRPv/NatW0uSDhw4kOA6nn76af3yyy+aOXOmAgICHqKZAAAAAAAAQOpnd9iWKVMmSdKFCxfinR87PbZcYpo1a6b9+/fbWzUAAAAAAACQJtgdtlWuXFnGGPXv31///vuvzbxTp05pwIABslgsqlSpkl3r8/b2friWAgAAAAAAAKlcRnsLDhs2TGvXrtWBAwdUsGBBVahQQYGBgTp9+rQ2bdqk6OhoeXh4aMiQIcnZXgAAAAAAACDVsjtsK168uFatWqU333xThw4d0rp162zmFyhQQFOnTlWpUqWc3UYAAAAAAAAgTbA7bJOkChUqaP/+/dq0aZN27typyMhI+fn5qUSJEqpUqZIsFktytRMAAAAAAABI9R4qbJMki8WiihUrqmLFisnRHgAAAAAAACDNsnuABAAAAAAAAACJI2wDAAAAAAAAnISwDQAAAAAAAHCSdBm2jRgxQi+88IJ8fHyUI0cONWzYUAcOHEjpZgEAAAAAACCdS5dhW3h4uDp37qzff/9dq1ev1p07d1SrVi1dv349pZsGAAAAAACAdOyhRyNNC1asWGHz97Rp05QjRw5t375dVapUSaFWAQAAAAAAIL1Ll2HbgyIjIyVJ/v7+CZaJjo5WdHS09e8rV64ke7sAAAAAAACQvqTL20jvZ4xRz549ValSJRUrVizBciNGjJCfn5/1FRQU9BhbCQAAAAAAgPQg3YdtXbp00e7duzV79uxEy/Xv31+RkZHW14kTJx5TCwEAAAAAAJBepOvbSLt27arFixdr/fr1ypMnT6Jl3d3d5e7u/phaBgAAAAAAgPQoXYZtxhh17dpVixYt0rp165Q/f/6UbhIAAAAAAACeAOkybOvcubNmzZqln376ST4+Pjp9+rQkyc/PTx4eHincOgAAAAAAAKRX6fKZbZMmTVJkZKSqVq2qwMBA62vu3Lkp3TQAAAAAAACkY+myZ5sxJqWbAAAAAAAAgCdQuuzZBgAAAAAAAKQEwjYAAAAAAADASQjbAAAAAAAAACchbAMAAAAAAACchLANAAAAAAAAcBLCNgAAAAAAAMBJCNsAAAAAAAAAJyFsAwAAAAAAAJyEsA0AAAAAAABwEsI2AAAAAAAAwEkI2wAAAAAAAAAnIWwDAAAAAAAAnISwDQAAAAAAAHASwjYAAAAAAADASQjbAAAAAAAAACchbAMAAAAAAACchLANAAAAAAAAcBLCNgAAAAAAAMBJCNsAAAAAAAAAJyFsAwAAAAAAAJyEsA0AAAAAAABwEsI2AAAAAAAAwEkI2wAAAAAAAAAnIWwDAAAAAAAAnISwDQAAAAAAAHASwjYAAAAAAADASQjbAAAAAAAAACchbAMAAAAAAACchLANAAAAAAAAcBLCNgAAAAAAAMBJCNsAAAAAAAAAJyFsAwAAAAAAAJyEsA0AAAAAAABwEsI2AAAAAAAAwEkI2wAAAAAAAAAnIWwDAAAAAAAAnISwDQAAAAAAAHASwjYAAAAAAADASQjbAAAAAAAAACchbAMAAAAAAACchLANAAAAAAAAcBLCNgAAAAAAAMBJCNsAAAAAAAAAJyFsAwAAAAAAAJyEsA0AAAAAAABwEsI2AAAAAAAAwEkI2wAAAAAAAAAnIWwDAAAAAAAAnISwDQAAAAAAAHASwjYAAAAAAADASQjbAAAAAAAAACchbAMAAAAAAACchLANAAAAAAAAcBLCNgAAAAAAAMBJCNsAAAAAAAAAJyFsAwAAAAAAAJyEsA0AAAAAAABwEsI2AAAAAAAAwEkI2wAAAAAAAAAnIWwDAAAAAAAAnISwDQAAAAAAAHASwjYAAAAAAADASdJ12PbFF18of/78ypQpk5577jlt2LAhpZsEAAAAAACAdCzdhm1z585Vjx499MEHH2jnzp2qXLmyateurePHj6d00wAAAAAAAJBOpduwbcyYMWrXrp3eeustPf300xo3bpyCgoI0adKklG4aAAAAAAAA0ql0GbbdunVL27dvV61atWym16pVS5s2bUqhVgEAAAAAACC9y5jSDUgO58+f1927d5UzZ06b6Tlz5tTp06fjXSY6OlrR0dHWvyMjIyVJV65csbveu9E3H6G1cMTD7J+HdTXqbrKtG/FLzv155+adZFs34pec+/P6Hfbn45ac+1OSbkbfSNb1I67k3KdRt28n27oRv+Tcn9eirifbuhG/5Nyf9//mweOR3OfQGzf43fK4Jec+vXuDY+7j9jD7M7asMSbRchaTVIk06OTJk8qdO7c2bdqk8uXLW6d//PHH+v7777V///44ywwePFhDhgx5nM0EAAAAAABAGnPixAnlyZMnwfnpsmdbtmzZ5OLiEqcX29mzZ+P0dovVv39/9ezZ0/p3TEyMLl68qKxZs8pisSRre1PSlStXFBQUpBMnTsjX1zelmwMHsT/TH/Zp+sL+TF/Yn+kL+zP9YZ+mL+zP9IX9mb48SfvTGKOrV68qV65ciZZLl2Gbm5ubnnvuOa1evVqvvPKKdfrq1avVoEGDeJdxd3eXu7u7zbTMmTMnZzNTFV9f33T/pXiSsD/TH/Zp+sL+TF/Yn+kL+zP9YZ+mL+zP9IX9mb48KfvTz88vyTLpMmyTpJ49e6ply5Z6/vnnVb58eU2ZMkXHjx9Xhw4dUrppAAAAAAAASKfSbdjWtGlTXbhwQUOHDtWpU6dUrFgx/fzzzwoODk7ppgEAAAAAACCdSrdhmyR16tRJnTp1SulmpGru7u4aNGhQnFtokTaxP9Mf9mn6wv5MX9if6Qv7M/1hn6Yv7M/0hf2ZvrA/40qXo5ECAAAAAAAAKSFDSjcAAAAAAAAASC8I2wAAAAAAAAAnIWwDAAAAAAAAnISwDTaqVq2qHj16pHQz4GTs10dnsVj0448/2l0+X758Gjdu3CMvj4czZcoUBQUFKUOGDDbvO2wNHjxYJUuWTOlmAHZ5XMfNB4/XAPAkW7dunSwWiy5fvpzSTUEax2/Pewjb0og2bdrIYrFYX1mzZtVLL72k3bt3p3TTYIf79118rzZt2qR0E59Ip0+fVteuXVWgQAG5u7srKChI9erV09q1a61lTp06pdq1a9u9zj/++ENvv/223eXPnj2rd955R3nz5pW7u7sCAgIUFhamzZs3P9S2pJSjR4/KYrFo165dD7WcM7b7ypUr6tKli/r27av//vtPb7/9dpo7uVetWjXeY0KHDh2cWs97771n87l+Et1/HnV1dVXOnDlVs2ZNTZ06VTExMU6rhwAnaWn9uIek2XN+ddTjPN4TQjycB3+3xL7+/vvvlG5amvU4fgtWqFBBp06dkp+fn9PW6Ww3b97UoEGDVKRIEbm7uytbtmxq3Lix/vrrr5RuWqqX1Lk3tXcQaNOmjRo2bJjSzXgoGVO6AbDfSy+9pGnTpkm6dxEzYMAA1a1bV8ePH0/hliXs1q1bcnNzS+lmpLhTp05Z/3/u3LkaOHCgDhw4YJ3m4eGREs1yyO3bt+Xq6prSzXhkR48eVcWKFZU5c2Z99tlnKl68uG7fvq2VK1eqc+fO2r9/vyQpICDgodabPXv2hyr/6quv6vbt25o+fboKFCigM2fOaO3atbp48eJDred+aWHfOGO7jx8/rtu3b+vll19WYGBgMrY2ccYY3b17VxkzPtoptX379ho6dKjNNE9PT2c0zcrb21ve3t5OXeejSOlzQux59O7duzpz5oxWrFih7t2764cfftDixYsfeR8mh5R+r5JTchz3niSp/bNh7/n1cXD0+Oxsqa09yen+3y2xHvYa6e7du7JYLMqQ4fH0D0nt363k/i3o5ub20Ne9j1N0dLRq1Kih48ePa/To0SpbtqzOnDmjESNGqGzZslqzZo3KlSuX0s20Sm3X45x7U4BBmtC6dWvToEEDm2nr1683kszZs2eNMcb06dPHFCpUyHh4eJj8+fObAQMGmFu3blnLDxo0yJQoUcJ89913Jjg42Pj6+pqmTZuaK1euWMuEhoaa7t27W/9evny58fX1NdOnTzfGGPPvv/+aJk2amMyZMxt/f39Tv359c+TIkTjtHD58uAkMDDTBwcFOfy/SumnTphk/Pz+baYsXLzalS5c27u7uJn/+/Gbw4MHm9u3b1vmjR482xYoVM56eniZPnjymY8eO5urVqzbr2Lhxo6lSpYrx8PAwmTNnNrVq1TIXL140xtzbr127djW9e/c2WbJkMTlz5jSDBg2yWf7y5cumffv2Jnv27MbHx8dUq1bN7Nq1yzo/9vPzzTffmPz58xuLxWJiYmKc++Y8RrVr1za5c+c2165dizPv0qVL1v+XZBYtWmSMMaZcuXKmb9++NmXPnj1rMmbMaH755RdjjDHBwcFm7Nix8S4fXz2SzLp16xJt66Psmy+//NLkypXL3L1712Zd9erVM61atTLGGPP333+b+vXrmxw5chgvLy/z/PPPm9WrV9uUDw4ONh9//LF58803jbe3twkKCjKTJ0+22b77X6GhoYluy8Ns97Fjx0z9+vWNl5eX8fHxMa+99po5ffq0Mebe9+jBulu3bh1n2pEjR0zp0qXNqFGjrOtt0KCBcXFxMZGRkcYYY06dOmUkmf379xtjjPn+++/Nc889Z7y9vU3OnDlNs2bNzJkzZ6zL//rrr0aSWbFihXnuueeMq6ur+eWXX0xMTIz59NNPTf78+U2mTJlM8eLFzfz58xPdxgePuQ86cuSIkWQWLFhgqlatajw8PEzx4sXNpk2bbMpNmTLF5MmTx3h4eJiGDRua0aNH2xxnYj8jsWKP1SNHjjQBAQHG39/fdOrUyeacER0dbXr37m1y5cplPD09TZkyZcyvv/5qU+9vv/1mKleubDJlymTy5MljunbtavOdCg4ONsOGDTOtW7c2vr6+1s9eSojvPGqMMWvXrjWSzFdffWWMSfxzF+unn34yzz33nHF3dzdZs2Y1r7zyijHm3v588DMY64cffjBFixY1bm5uJjg42OYzaUzqeq+Skz3f/9j90bBhQ+Ph4WEKFixofvrpJ5sy69atMy+88IJxc3MzAQEBpm/fvjbnzdDQUNO5c2fTuXNn4+fnZ/z9/c0HH3xgc9568Hg9depU4+vra1atWmWMMeavv/4ytWvXNl5eXiZHjhzmjTfeMOfOnbOWT+o7H3usWLp0qSlevLhxd3c3ZcqUMbt377bZlrT0PbKHPefXpL5nSV2zJnS8T+j4bM/5LioqyvTu3dvkyZPHuLm5mYIFC5qvv/7aehx+8HwTu0zXrl1N9uzZjbu7u6lYsaLZunWrdZ0JtSe9S+h4m9T1bOw18pIlS8zTTz9tXFxczD///GP9DrRs2dJ4eXmZvHnzmh9//NGcPXvW+jkqVqyY+eOPP2zqS0/fLXt+C8Z+3u6/jt25c6f1+2GMMUePHjV169Y1mTNnNp6enqZo0aJm2bJl8S4fuz9WrFhhQkJCjJeXlwkLCzMnT560acfUqVNNSEiIcXd3N0WKFDETJ060zouOjjadO3c2AQEBxt3d3QQHB5vhw4db5w8aNMgEBQUZNzc3ExgYaLp27Zrge/DJJ58Yi8Vicw1sjDF37941zz//vClatKiJiYkxu3fvNhaLxXq8vnjxorFYLKZx48bWZYYPH27KlStns91r1qwxzz33nPHw8DDly5e3XhfGSur3miQzadIkU79+fePp6WkGDhyY4LY8bkmde4ODg22OcbG/4eP73HXv3t3mev/atWvW72ZAQIAZNWpUnOvbpK4pk/qsDRo0KM5x+MFr0tSIsC2NePCDfvXqVfPOO++YggULWn9MDxs2zPz222/myJEjZvHixSZnzpzm008/tS4zaNAg4+3tbRo1amT27Nlj1q9fbwICAsz7779vLXP/F2P27NnGx8fH/Pjjj8YYY65fv24KFSpk2rZta3bv3m327dtnmjdvbooUKWKio6Ot7fT29jYtW7Y0e/fuNXv27EnmdybteTBsW7FihfH19TXffvutOXz4sFm1apXJly+fGTx4sLXM2LFjzS+//GL++ecfs3btWlOkSBHTsWNH6/ydO3cad3d307FjR7Nr1y6zd+9eM378eOtJJjQ01Pj6+prBgwebgwcPmunTpxuLxWL9QRETE2MqVqxo6tWrZ/744w9z8OBB06tXL5M1a1Zz4cIFY8y9z0/sgW/Hjh3mzz//TLNh24ULF4zFYrE52Sfk/rBs/PjxJm/evDbbPX78eJM7d27r9/Bhwrbbt28bb29v06NHDxMVFRVvmUfdN+fPnzdubm5mzZo11nVdvHjRuLm5mZUrVxpjjNm1a5f58ssvze7du83BgwfNBx98YDJlymSOHTtmXSY4ONj4+/ubiRMnmkOHDpkRI0aYDBkymIiICGOMMVu3brVeoJw6dcrapsTYu92lSpUylSpVMtu2bTO///67KV26tPXkfuPGDbNmzRojyWzdutWcOnXKXL582ZQvX960b9/enDp1ypw6dcrcuXPH9OzZ09StW9e6Xn9/f5MtWzbrxeWsWbNMQECAte5vvvnG/Pzzz+bw4cNm8+bNply5cqZ27drW+bEXZcWLFzerVq0yf//9tzl//rx5//33TUhIiFmxYoU5fPiwmTZtmnF3d080VLA3bAsJCTFLly41Bw4cMI0bNzbBwcHWC7yNGzeaDBkymJEjR5oDBw6YiRMnGn9//yTDNl9fX9OhQwcTERFhlixZYjw9Pc2UKVOsZZo3b24qVKhg1q9fb/7++28zcuRI4+7ubg4ePGiMMWb37t3G29vbjB071hw8eND89ttvplSpUqZNmzbWdcT+SB45cqQ5dOiQOXToUILbmtwS+vFnjDElSpQwtWvXTvJzZ4wxS5cuNS4uLmbgwIFm3759ZteuXebjjz82xtw7tuTJk8cMHTrU+hk0xpht27aZDBkymKFDh5oDBw6YadOmGQ8PDzNt2jTrelPTe5Wc7Pn+SzJ58uQxs2bNMocOHTLdunUz3t7e1uPLv//+azw9PU2nTp1MRESEWbRokcmWLZvNPyKFhoYab29v0717d7N//34zY8aMOJ/x+4/XI0eONP7+/mbz5s3GGGNOnjxpsmXLZvr3728iIiLMjh07TM2aNU21atWsyyf1nY89Vjz99NNm1apVZvfu3aZu3bomX7581mA7rX2PkmLP+dWe71lS16wJHe8TOj7bc75r0qSJCQoKMgsXLjSHDx82a9asMXPmzDF37twxCxYsMJLMgQMHrOcbY4zp1q2byZUrl/n555/NX3/9ZVq3bm2yZMli/awm1J70LqHjbVLXs9OmTTOurq6mQoUK5rfffjP79+83165ds16LfPnll+bgwYOmY8eOxsfHx7z00ktm3rx55sCBA6Zhw4bm6aeftl6jpbfvlj2/Be0J215++WVTs2ZNs3v3bnP48GGzZMkSEx4eHu/ysfujRo0a5o8//jDbt283Tz/9tGnevLl1/VOmTDGBgYFmwYIF5p9//jELFiww/v7+5ttvvzXG3Du2BgUFmfXr15ujR4+aDRs2mFmzZhljjJk/f77x9fU1P//8szl27JjZsmWLzTH6QcWLFze1atWKd97MmTONJLNz504TExNjsmXLZn744QdjjDE//vijyZYtm8mRI4e1fK1ataz/gB673WXLljXr1q0zf/31l6lcubKpUKGCtbw9v9ckmRw5cphvvvnGHD582Bw9ejTBbXnckjr3nj171kgy06ZNM6dOnbIGuPaEbR07djR58uSxOc/Fnn9jJXVNmdRn7erVq6ZJkybmpZdesh7zY/OH1IywLY1o3bq1cXFxMV5eXsbLy8tIMoGBgWb79u0JLvPZZ5+Z5557zvr3oEGDjKenp01Ptt69e5uyZcta/4794Tdx4kTj5+dn869v33zzjSlSpIhN0BAdHW08PDysP95bt25tcubMmSY+/CnlwbCtcuXKcS5Kv//+exMYGJjgOubNm2eyZs1q/btZs2amYsWKCZYPDQ01lSpVspn2wgsvWE8ya9euNb6+vnEOvk899ZS1F9OgQYOMq6ur9eCblm3ZssVIMgsXLkyy7P1hWWwvtvXr11vnly9f3vTu3dv698OEbcbc6+2SJUsWkylTJlOhQgXTv39/8+eff1rnO7Jv6tevb9q2bWv9e/LkySYgIMDcuXMnwfYULVrUjB8/3mZ73njjDevfMTExJkeOHGbSpEnGmP8Lg3bu3JngOh9lu1etWmVcXFzM8ePHrdP++usva7hmTNwLSGPiD68WL15s/Pz8zN27d82uXbtM9uzZzbvvvmvdb2+//bZp2rRpgm2NDRRj//U99qIs9h8ijLn3r3qZMmWK0+OsXbt2plmzZgmuOzQ01Li6ulqP7bGv2IvU2Pf366+/jvM+xAaeTZs2NS+//LLNelu0aJFk2BYcHGzzWXjttdes78Pff/9tLBaL+e+//2zW++KLL5r+/fsbY4xp2bKlefvtt23mb9iwwWTIkMHcvHnTGHPv89OwYcMEt/9xSixsa9q0qTUQSepzV758edOiRYsE63nwGGDMvYvMmjVr2kzr3bu3KVq0qM1yqeW9Sm5Jff8lmQEDBlj/vnbtmrFYLGb58uXGmHsh14PXIxMnTjTe3t7WH52hoaE2P7yNMaZv377m6aeftv4du6/69etnAgMDbXqcffjhh3F+1J04ccIauNjznY89VsyZM8c6/8KFC8bDw8PMnTvXGJP2vkdJsef8as/37GGuWe8X3/E5Ifef7w4cOGAkxent9uB67w8xrl27ZlxdXc3MmTOt027dumVy5cplPvvss4duT3ry4O8WLy8vm15FsR68no3ttf5gz6UHr0Vie6R/+OGH1mmbN282kqz/yJHevlv2/Ba0J2x79tlnbQKi+8UXtkkyf//9t7XMxIkTTc6cOa1/BwUFWcOzWMOGDTPly5c3xhjTtWtXU7169Xj/gX706NGmcOHCNr3qE5MpU6YE/4Fyx44dRpL12NqoUSPTpUsXY4wxPXr0ML169TLZsmUzf/31lzV4ij2n3N+zLdayZcuMJOtnxZ7fa5JMjx497NqWlGDPuffB3yxJhW1Xr141bm5u8Z7nYveVPdeU9nzWEruOS60YICENqVatmnbt2qVdu3Zpy5YtqlWrlmrXrq1jx45Jkn744QdVqlRJAQEB8vb21ocffhjnHv58+fLJx8fH+ndgYKDOnj1rU2bBggXq0aOHVq1apWrVqlmnb9++XX///bd8fHysz//x9/dXVFSUDh8+bC337LPPpurnHaQ227dv19ChQ63vqbe3t9q3b69Tp07pxo0bkqRff/1VNWvWVO7cueXj46NWrVrpwoULun79uiRp165devHFFxOtp3jx4jZ/37/vt2/frmvXrilr1qw27Thy5IjNvg0ODn7o522kRsYYSfceBPowsmfPrpo1a2rmzJmSpCNHjmjz5s1q0aLFI7fl1Vdf1cmTJ7V48WKFhYVp3bp1Kl26tL799ltJju2bFi1aaMGCBYqOjpYkzZw5U6+//rpcXFwkSdevX1efPn1UtGhRZc6cWd7e3tq/f3+c48b9nx2LxaKAgIA4xw1nb3dERISCgoIUFBRkXSa2nREREQ9VV5UqVXT16lXt3LlT4eHhCg0NVbVq1RQeHi7p3oOvQ0NDreV37typBg0aKDg4WD4+PqpataokxXlfnn/+eev/79u3T1FRUapZs6bNfvruu+9s9lN8WrRoYT22x75eeeUVmzL374PY59PF7oMDBw6oTJkyNuUf/Ds+zzzzjPWzELve2HXu2LFDxhgVLlzYZnvCw8Ot27N9+3Z9++23NvPDwsIUExOjI0eOxPs+pVbGGFksFrs+d/Ycbx8UERGhihUr2kyrWLGiDh06pLt371qnpYX3yhmS+v5Ltp95Ly8v+fj4WD+fERERKl++vM0xvGLFirp27Zr+/fdf67Ry5crZlClfvnyc93z06NGaPHmyNm7cqGeffdY6ffv27fr1119tPt8hISGSpMOHDz/Ud758+fLW//f391eRIkWsn6f09D2S7Du/2nt8t+eaNSEPvl9Jne927dolFxcXm3NBUg4fPqzbt2/bfLddXV1VpkyZOOeptLL/nOn+3y27du3S//73vySvZ6V7zw178JpVsj0m5MyZU5JsvrOx0+6/tk1P3y0p6d+C9ujWrZs++ugjVaxYUYMGDUpygAVPT0899dRT1r/v/x6eO3dOJ06cULt27Wze548++sh6HGzTpo127dqlIkWKqFu3blq1apV1Xa+99ppu3rypAgUKqH379lq0aJHu3LnzMG+J1YPHnqpVq2rdunWSpPDwcFWrVk1VqlRReHi4/vjjD928eTPOeTmxay17fq9JqfvzZM+592EdPnxYt27divc8F8uea0op8c9aWpX+n86Zjnh5ealgwYLWv5977jn5+fnpq6++Ut26dfX6669ryJAhCgsLk5+fn+bMmaPRo0fbrOPBhzRaLJY4o7CVLFlSO3bs0LRp0/TCCy9YD1oxMTF67rnnrEHD/e7/ke/l5eXwtj5JYmJiNGTIEDVq1CjOvEyZMunYsWOqU6eOOnTooGHDhsnf318bN25Uu3btdPv2bUn2DbCQ2L6PiYlRYGCg9aR0v8yZM1v/P73s20KFCll/WD/sqDYtWrRQ9+7dNX78eM2aNUvPPPOMSpQo4VB7MmXKpJo1a6pmzZoaOHCg3nrrLQ0aNEht2rRxaN/Uq1dPMTExWrZsmV544QVt2LBBY8aMsc7v3bu3Vq5cqVGjRqlgwYLy8PBQ48aNdevWLZv12HPceBSJbXds+PGghKYnxs/PTyVLltS6deu0adMmVa9eXZUrV9auXbt06NAhHTx40BqoXb9+XbVq1VKtWrU0Y8YMZc+eXcePH1dYWFic9+X+9zz2/Vi2bJly585tU87d3T3J9t1/bI/P/fvg/mOyFP97EnvRae86Y9d7/zHBxcVF27dvtwnkJFkHWoiJidE777yjbt26xVl33rx5rf+fFo4bERERyp8/v12fu0cZ0MbefZQW3itnSez7LyX++Uzs/XzY40PlypW1bNkyzZs3T/369bNOj4mJUb169fTpp5/GWSYwMFB79+6V9Gjf+fvbmZ6+R5J951d7j++OnHsefL+SOt896vc6tl2JbUd87XkSPPi7xZ7rWenevojv8xHfeTCxc2N6+25Jif8W/Oijj6wDSdx/frn/vZWkt956S2FhYVq2bJlWrVqlESNGaPTo0eratWu8dcb3PYxdf+x7/dVXX6ls2bI25WKvHUqXLq0jR45o+fLlWrNmjZo0aaIaNWrohx9+UFBQkA4cOKDVq1drzZo16tSpk0aOHKnw8PB4BxYoXLiw9u3bF287YwdeKVSokKR7YVv37t31999/a+/evapcubIOHz6s8PBwXb58Wc8995xNmP/gtsb3eUrs91qs1P55Surc+6AMGTLEuV65/zNlz/WmPdeUUuKftbSKsC0Nix2d5+bNm/rtt98UHBysDz74wDr/Yf6V435PPfWURo8erapVq8rFxUUTJkyQdO9gOXfuXOXIkUO+vr5O2Qbce18PHDiQ4I/tbdu26c6dOxo9erT1JDpv3jybMsWLF9fatWs1ZMiQR27D6dOnlTFjRuXLl++R1pGW+Pv7KywsTBMnTlS3bt3inBgvX75sE2Tdr2HDhnrnnXe0YsUKzZo1Sy1btnR6+4oWLWodetuRfePh4aFGjRpp5syZ+vvvv1W4cGE999xz1vkbNmxQmzZtrL2orl27pqNHjz5UHbG9WO/vKfKo7t/uokWL6vjx4zpx4oS198O+ffsUGRmpp59+OtH2xNeWqlWr6tdff9WWLVs0dOhQZc6cWUWLFtVHH32kHDlyWNe5f/9+nT9/Xp988om13m3bttnVdnd3dx0/fvyhekY4Q0hIiLZu3WozzZ42J6ZUqVK6e/euzp49q8qVK8dbpnTp0vrrr7+SDApTu19++UV79uzRu+++qzx58iT5uYs93r755pvxri++z2DRokW1ceNGm2mbNm1S4cKF41x4Pqnu//7bU3bBggU2ocamTZvk4+NjE3z9/vvvNsv9/vvvKlSokM17XqZMGXXt2lVhYWFycXFR7969Jd37fC9YsED58uWLd+TIh/nO//7779Yf95cuXdLBgwetveTSy/colj3n10c9vj8ooeN9fJI63z377LOKiYlReHi4atSoEW9dku25rmDBgnJzc9PGjRvVvHlzSfd+hG7btk09evSwezueFPZczzpTevtuxef+34LS/3V+OHXqlLJkySLpXq/NBwUFBalDhw7q0KGD+vfvr6+++irBsC0xOXPmVO7cufXPP/8kepeHr6+vmjZtqqZNm6px48Z66aWXdPHiRfn7+8vDw0P169dX/fr11blzZ4WEhGjPnj0qXbp0nPW8/vrr+uCDD/Tnn3/a/EN3TEyMxo4dq6JFi1qnFytWTFmzZtVHH32kEiVKyNfXV6GhoRoxYoQuXbr00NdqSf1eS6vuP/e6urrGOaZmz57d+o9LsXbt2mUNxgoWLChXV9d4z3Ox77E915T2eJhjfmrBbaRpSHR0tE6fPq3Tp08rIiJCXbt21bVr11SvXj0VLFhQx48f15w5c3T48GH973//06JFix65rsKFC+vXX3+13lIq3evRky1bNjVo0EAbNmzQkSNHFB4eru7du9vctoGHM3DgQH333XcaPHiw/vrrL0VERGju3LkaMGCApHvh5507dzR+/Hj9888/+v777/Xll1/arKN///76448/1KlTJ+3evVv79+/XpEmTdP78ebvaUKNGDZUvX14NGzbUypUrdfToUW3atEkDBgxw+Ed7avXFF1/o7t27KlOmjBYsWKBDhw4pIiJC//vf/2y6Qj/Iy8tLDRo00IcffqiIiAjrBfajuHDhgqpXr64ZM2Zo9+7dOnLkiObPn6/PPvtMDRo0kOT4vmnRooWWLVumqVOn6o033rCZV7BgQS1cuFC7du3Sn3/+qebNmz90j7UcOXLIw8NDK1as0JkzZxQZGem07S5evLhatGihHTt2aOvWrWrVqpVCQ0MT7aKfL18+bdmyRUePHtX58+et21O1alWtWLFCFotFRYsWtU6bOXOmzQVX3rx55ebmZv2+LV68WMOGDUtym3x8fPTee+/p3Xff1fTp03X48GHt3LlTEydO1PTp0xNd9saNG9Zje+zr0qVLSdYZq2vXrvr55581ZswYHTp0SJMnT9by5csfuofP/QoXLqwWLVqoVatWWrhwoY4cOaI//vhDn376qX7++WdJUt++fbV582Z17tzZ2ktw8eLFj3TB/rjEnkf/++8/7dixQ8OHD1eDBg1Ut25dtWrVyq7P3aBBgzR79mwNGjRIERER2rNnjz777DNrHfny5dP69ev133//WY/BvXr10tq1azVs2DAdPHhQ06dP14QJE/Tee++lyPuQkuz5/ielU6dOOnHihLp27ar9+/frp59+0qBBg9SzZ0/rj3hJOnHihHr27KkDBw5o9uzZGj9+vLp37x5nfeXLl9fy5cs1dOhQjR07VpLUuXNnXbx4Uc2aNdPWrVv1zz//aNWqVWrbtq3u3r37UN/5oUOHau3atdq7d6/atGmjbNmyWXt9pcXvUVKSOr8+6vH9QQkd7+OT1PkuX758at26tdq2basff/xRR44c0bp166xhUHBwsCwWi5YuXapz587p2rVr8vLyUseOHdW7d2+tWLFC+/btU/v27XXjxg21a9fu0d/AdMqe61lnSo/frcR+C0r3PudBQUEaPHiwDh48qGXLlsW5y6lHjx5auXKljhw5oh07duiXX355qJD7QYMHD9aIESP0+eef6+DBg9qzZ4+mTZtmvZNi7NixmjNnjvbv36+DBw9q/vz5CggIUObMmfXtt9/qm2++0d69e62fCQ8PDwUHB8db17vvvqsyZcqoXr16mj9/vo4fP64//vhDr776qiIiIvTNN99Yr30sFouqVKmiGTNmWO9eKF68uG7duqW1a9dap9krqd9rqZ095958+fJp7dq1Nteh1atX17Zt2/Tdd9/p0KFDGjRokE345u3trXbt2ql3794257n7z8X2XFPaI1++fNq9e7cOHDig8+fPx+m1mSo9rofDwTEPDnHu4+NjXnjhBesoK8bce3Bs1qxZjbe3t2natKkZO3Zsog/INubeqECxQ/saE/dhs/v27TM5cuQwPXv2NMbceyBpq1atTLZs2Yy7u7spUKCAad++vYmMjLS2M609uPBxe3CABGPujXBToUIF4+HhYXx9fU2ZMmVsRuMZM2aMCQwMNB4eHiYsLMx89913cR6Aum7dOlOhQgXj7u5uMmfObMLCwqzz43uIcIMGDaxD1xtjzJUrV0zXrl1Nrly5jKurqwkKCjItWrSwPsA4vs9PWnfy5EnTuXNnExwcbNzc3Ezu3LlN/fr1bYaSVjwPC419aGqVKlXirPNhBkiIiooy/fr1M6VLlzZ+fn7G09PTFClSxAwYMMDcuHHDWs6RfXPnzh0TGBhoJJnDhw/bzDty5IipVq2a8fDwMEFBQWbChAlxPivxPey9RIkSNqP+ffXVVyYoKMhkyJDBZnSihNi73ceOHTP169c3Xl5exsfHx7z22mvm9OnT1vnxDZBw4MABU65cOePh4WEz7/Lly8bFxcXmAc2LFi0yksyECRNs2jdr1iyTL18+4+7ubsqXL28WL15sMwhEfA8gNube4BGff/65KVKkiHF1dTXZs2c3YWFh1lG+4hMaGhpnKHNJJiwszBgT/wAUscO33/85nTJlismdO7fx8PAwDRs2NB999JHNCKvxDZCQ1OhSt27dMgMHDjT58uUzrq6uJiAgwLzyyis2D5HfunWrqVmzpvH29jZeXl6mePHi1pE5jYn/85NS7j+PZsyY0WTPnt3UqFHDTJ061fpQfWOS/twZY8yCBQtMyZIljZubm8mWLZtp1KiRdd7mzZtN8eLFjbu7u7n/MuuHH34wRYsWNa6uriZv3rxm5MiRNutMTe9VcrLn+x/fcdPPz89m9NZ169aZF154wbi5uZmAgADTt29f6wi9xtz7bnXq1Ml06NDB+Pr6mixZsph+/frZPKT7wfc8PDzceHl5mc8//9wYY8zBgwfNK6+8YjJnzmw8PDxMSEiI6dGjh3UdSX3nY48VS5YsMc8884xxc3MzL7zwQpyHv6el75G9kjq/JvU9s+eaNb7jfULHZ3vOdzdv3jTvvvuuCQwMNG5ubqZgwYJm6tSp1vlDhw41AQEBxmKxWK+fbt68abp27Wq9Lq5YsaJ1kAdjEj5fpHcJ/R5I6no2vmtkY+L/Djx4nIjvfJmevlv2/BY05t4I5c8++6zJlCmTqVy5spk/f77N9VCXLl3MU089Zdzd3U327NlNy5YtrSPkxjdAwoP7I/ba6X4zZ860nhOzZMliqlSpYh0kZcqUKaZkyZLGy8vL+Pr6mhdffNHs2LHDuq6yZcsaX19f4+XlZcqVK2czSEF8rl+/bgYMGGAKFixoXF1djb+/v3n11VfNnj174pQdP368kWSWLl1qndagQQPj4uJi/e0a33YbE/81ZlK/1xK75k9p9px7Fy9ebAoWLGgyZsxoc6wdOHCgyZkzp/Hz8zPvvvuu6dKli8314tWrV80bb7xhPD09Tc6cOc1nn30W5/ia1DWlPZ+1s2fPWr/PD14Hp1YWY9L4jbAAAMBG+/bttX//fm3YsCGlmwKkiKpVq6pkyZIaN25cirVh3bp1qlatmi5dupTgowkAAED6xDPbAABI40aNGqWaNWvKy8tLy5cv1/Tp0/XFF1+kdLMAAACAJxJhGwAAadzWrVv12Wef6erVqypQoID+97//6a233krpZgEAAABPJG4jBQAAAAAAAJyE0UgBAAAAAAAAJyFsAwAAAAAAAJyEsA0AAAAAAABwEsI2AAAAAAAAwEkI2wAAAJBmWSwWWSwWDR48OKWbAgAAIImwDQAAQJGRkZo4caLq1KmjfPnyydPTU35+fipcuLBatGihuXPn6u7duyndTAAAAKQBhG0AAOCJ9vXXX+upp55Sly5dtHz5ch07dkw3b97UlStXdOjQIc2aNUuvv/66ihcvro0bN6Z0c58I+fLlk8ViUZs2bVK6KQAAAA8tY0o3AAAAIKX07t1bo0aNkiRlzJhRr7/+uurXr6/g4GDdunVLBw4c0OzZs7V27Vrt27dPNWrU0IwZM9S4ceMUbjliGWNSugkAAAA2CNsAAMATaeLEidagLSgoSEuWLFGJEiVsylSqVEnt2rXT3Llz1apVK0VHR6tFixYqWLCgSpYsmQKtBgAAQGrHbaQAAOCJc+zYMb333nuSJG9vb/3yyy9xgrb7NW3aVNOnT5ck3bp1Sy1btqRHFQAAAOJF2AYAAJ4448aNU1RUlCRp0KBBKliwYJLLvP7663r55ZclSXv37tXSpUvjLRcTE6PZs2fr1VdfVd68eeXh4aGsWbOqRIkSatu2rVasWKE7d+4kWM9vv/2mt956S0WKFJGvr6+8vb0VEhKihg0b6rvvvtOVK1dsyn/77bfWETmPHj2a4HqPHj1qLfftt9/Gmd+mTRtZLBbly5dPkvTff/+pZ8+eKly4sDw9PZU9e3bVqVNHy5cvT/R9un79uubOnau33npLJUuWlJ+fn1xdXZU9e3aFhoZq1KhRunbtWrzLVq1aVRaLRceOHZMkTZ8+3drm2FfVqlVtlrFnNNKYmBjNmDFDderUUUBAgNzc3JQ9e3ZVq1ZNX3zxhW7dupXgsoMHD7bWIUlRUVEaOXKkSpcuLR8fH/n4+KhMmTKaMGFCovsVAAA8QQwAAMATJCYmxvj7+xtJxsPDw1y+fNnuZVeuXGkkGUnmlVdeiTP/yJEjpmTJktYyCb1+/fXXOMveuHHDNGvWLMllBw0aZLPctGnTrPOOHDmSYNuPHDliLTdt2rQ481u3bm0kmeDgYPPHH3+YHDlyJNiG7t27J1hPaGhoktuQP39+ExER8UjLhoaG2iyT0PsS68KFC6ZixYqJrvPpp582R48ejXf5QYMGWcudPn3alChRIsH11KtXz9y9ezfB9wYAADwZeGYbAAB4ovz111+6ePGiJKlKlSry8/Oze9kXX3xRnp6eunHjRpyRSc+cOaOKFSvq5MmTkqTq1aurdevWCgkJkcVi0ZEjR/TLL79o/vz5cdYbExOjBg0aaPXq1ZKkQoUKqVOnTnr++efl6empU6dOadOmTZo3b96jbrbdbty4oddee02RkZHq16+f6tSpI3d3d23ZskUjRozQqVOn9Pnnnytv3rzq2bNnnOXv3LmjZ599VvXr19fzzz+vXLlyyRijY8eOadGiRZo3b56OHDmihg0bateuXcqUKZN12WnTpun69esKCwvTyZMn1aBBA3300Uc26/fy8rJ7W+7evau6detq8+bNkqTQ0FB16dJF+fPn18mTJzV16lT9+OOPioiI0Isvvqhdu3bJ29s7wfU1atRIERER6tatm+rVqyd/f38dOHBAw4YNU0REhJYsWaKvvvpK77zzjt1tBAAA6VBKp30AAACP04wZM6w9kfr37//Qy5cvX966/H///Wed3rBhQ+v0Tz/9NMHlr127Zi5evGgzbdy4cTY95qKiouJd9u7duzZ1GuP8nm2SjKurqwkPD49T5r///jN58uQxkoynp6c5c+ZMnDIHDx5MsA3GGLN69WqTIUMGI8l8/fXX8ZYJDg42kkzr1q0TXZcxifdsmzBhgnV+q1atTExMTJwy77//vrVMnz594sy/v2ebq6trvL0SL1y4YHLmzGkkmeLFiyfZZgAAkL7xzDYAAPBEOX/+vPX/AwICHnr5nDlzWv//woULkqT9+/frp59+kiQ1aNBAffr0SXB5Ly8vZcmSxfp3TEyMRo4cKUnKnTu3vvvuO7m7u8e7bIYMGZQrV66HbvPDeuedd1SlSpU403PlyqXRo0dLutcDLnbQiPsVKlQo0XXXqFFD9evXlyT9+OOPjjc2ERMnTpQkZcuWTRMmTLA+d+1+Q4cOVUhIiCTpq6/+X3v3FhLV28Vx/FemaWSH0YqKGMwOFpV0onOGFQh204EK8tABI6iMoLoIwiSCqKCTFfRGZUJFGuFFdqMZYlqN2KRWRFoRFZbYgbDItP1eyOx3zD3jTP+hl3/z/cDAdvZez157z40s1vM8/9H37989jrd169Yua8ZJks1m07p16yRJNTU1+vz5cwCyBwAA/1YU2wAAQFD58uWLeezPlESrGNdmBUVFRebupNu3b/drPKfTqTdv3kiSMjIyvE5j/FNchSMrS5cu1YABAyRJxcXF3Y7V1NSkZ8+eqa6uzvwMGjRIkvTw4cOA5Gvl7du3evLkiSRp5cqVioyMtLwuJCTEfN6PHz+qurra45hr1qzxeG7q1Knm8YsXL34nZQAA8JdgzTYAABBU3IsunnbF9MY9pl+/fpKkBw8eSJJCQ0M1c+ZMv8ZzxUqy7Cb708LCwjRp0iSP50NDQzV58mSVlpaqrq7O8po7d+7o+PHjKi4uNtfHs+LeZRho7rnNmDHD67Xu5+vq6jRr1izL61wdcFZsNpt57F7QBQAAwYdiGwAACCpRUVHmcWNjo9/x79696zKWq2hks9k8TgH1xL3gNHToUL/zCTSbzaZevbz/i+iaSmtVSNu7d6+ys7N9ute3b9/8T9BH7rm5T/214j6d2FtxsE+fPh7P9ez5vwkj7e3tvqQIAAD+UkwjBQAAQSU+Pt48du8q80V7e7tqamokSYMGDeqyfprVmmD++KfxgeBLDq4ps78qKSkxC20jR47UqVOnVFNTo0+fPqmtrU2GYcgwDO3ZsyegOXenu2fy9DwAAAC/g842AAAQVCZMmCCbzaYPHz6orKxMnz9/Vv/+/X2KLS4u1tevXyVJc+fONb+Pjo6W1LFhQmtrq8LCwnzOxxUrdawzNnbsWJ9jpc4dVT9//vR4XUtLi0/jNTc3q729XSEhIR6vef/+vaTOUyeljg0GJGnAgAGqrKzU4MGDLeM/fvzoUy7/hHtu3XUwuncr/vpMAAAA/qKzDQAABJUePXooNTVVUsc0RleByBcnTpwwj9euXWseT5kyRZL048cPVVZW+pWPK1aSysrK/IqVOq9B562I9fTpU5/Ga21t9bpxQVtbm5xOp6SOwqW7R48eSZISExM9FtokqaqqymsOgejwc8/t3r17Xq+9f/++ZRwAAMDvoNgGAACCzrZt28y11bKzs1VfX99tzJUrV3Tjxg1J0vjx47VkyRLzXHJyslkgOnLkiF+5xMfHa8SIEZKks2fP+r1pQ0xMjHnsrYh16dIln8fMzc31eO769etmUW/RokWdzrW1tUmS2f1nxel06u7du17vHx4eLkn6/v27T/laGTZsmMaNGydJys/P97hpQXt7uy5cuCBJGjhwYKfiJwAAwO+g2AYAAIJOTEyMDh48KKljd9GFCxd67ea6evWq0tPTJXXs1pmXl9dp+uaYMWO0dOlSSVJhYaEOHTrkcayWlpZOHWg9e/bUzp07JUmvX79WWlqaWltbLWN//vypt2/fdvrONS1WknJyciwLVJcvX9a1a9c85vSr06dPq7y8vMv3jY2N2rFjh6SOzQJc78Rl9OjRkqTy8nI9f/68S3xTU5NSUlK6vb9ro4iGhgafc7ayefNm875bt261XJstOztbjx8/liRlZGT4vcEFAADAryi2AQCAoJSZmalt27ZJkl69eqVp06YpLS1NBQUFcjgcqqio0Llz57Ro0SKtWrXKXIvt4sWLlt1Pp06dMjdM2LVrlxYuXKi8vDw5HA5VVVWpoKBAW7Zskd1u71LY27x5sxYvXiypo3Ns4sSJOnbsmO7cuaMHDx7o5s2bysrKUlxcnM6cOdMptlevXtq4caMkqa6uTomJiSosLDTj1q9fr5SUFM2aNcun9+La+GHx4sXavXu3ysvL5XA4dPLkSU2dOlWvXr2SJO3bt6/LVNG0tDRJHQXMhIQE5eTkqLKyUhUVFTp8+LDi4+P1+PHjbnOZPXu2JMnhcOjAgQN6+PCh6uvrVV9frzdv3vj0HJK0adMm8165ublKTExUQUGBqqurdePGDS1fvlz79u2TJMXGxv7xjRsAAMBfygAAAAhip0+fNmw2myHJ6ycuLs64ffu217EaGhqMCRMmdDtWaWlpl9iWlhZjxYoV3cZmZWVZxs6cOdNjTEJCglFbW2v+ff78+S5jpKenG5IMu91uOBwOIzo62uN4mZmZHt/BunXrPMaFhIQYR48eNbKysszvrLx+/drjb5KQkNDpWm/vxTAMo7m52ZgzZ47Xdzpu3Djj5cuXlvHd5epSWlrq9fcFAADBg842AAAQ1DZt2qSGhgadOHFCSUlJGjFihMLDw9W3b1/FxsZq9erVunz5smpra5WQkOB1rJEjR8rpdOrChQtKTk7W0KFDFRYWpujoaMXHxysjI0PFxcWaP39+l9g+ffooPz9ft27dUmpqqmJiYhQREaHIyEjFxcVp2bJlunTpkjnl9NfYW7duaf/+/Zo4caIiIiLUr18/TZ8+XTk5OSopKVHfvn19fifTpk1TdXW1MjMzFRsbq/DwcEVFRSkpKUlFRUU6duyYx9hz584pLy9P8+bNU2RkpHr37i273a7U1FRVVFSY3YTeDB8+XPfv39eGDRs0atQocw2332Gz2VRWVqa8vDwlJSVpyJAhCg0NVVRUlBYsWKCcnBw5nU7Z7fbfvgcAAIC7HoZhsXgFAAAAgsratWuVm5sru92uly9f/r/TAQAA+Neisw0AAAAAAAAIEIptAAAAAAAAQIBQbAMAAAAAAAAChGIbAAAAAAAAECAU2wAAAAAAAIAAYTdSAAAAAAAAIEDobAMAAAAAAAAChGIbAAAAAAAAECAU2wAAAAAAAIAAodgGAAAAAAAABAjFNgAAAAAAACBAKLYBAAAAAAAAAUKxDQAAAAAAAAgQim0AAAAAAABAgFBsAwAAAAAAAALkv/RAhkOf0iy4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "df_Occupation=df.groupBy(col('Occupation').alias('Occupation')).count()\n",
    "df_Occupation=df_Occupation.orderBy('count',ascending=False)\n",
    "df_Occupation=df_Occupation.toPandas()\n",
    "df_Occupation['count']=round(df_Occupation['count']/sum(df_Occupation['count'])*100,2)\n",
    "df_Occupation=df_Occupation.head(10)\n",
    "sns.barplot(x=df_Occupation['Occupation'],y=df_Occupation['count']);\n",
    "for i, val in enumerate(df_Occupation.index):\n",
    "    y = df_Occupation['count'].loc[val].sum()\n",
    "    plt.text(i, y, str(round(y))+'%', ha=\"center\",fontsize = 15,         color ='black')\n",
    "plt.xlabel('Occupation',fontsize=20);\n",
    "plt.ylabel('% of Customers',fontsize=20);\n",
    "# Add legend outside the plot\n",
    "plt.legend(bbox_to_anchor=(1, 1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "356fe0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Existing Customer: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Employment Profile: string (nullable = true)\n",
      " |-- Occupation: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cat.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "736a2405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Income: integer (nullable = true)\n",
      " |-- Credit Score: integer (nullable = true)\n",
      " |-- Credit History Length: integer (nullable = true)\n",
      " |-- Number of Existing Loans: integer (nullable = true)\n",
      " |-- Loan Amount: integer (nullable = true)\n",
      " |-- Loan Tenure: integer (nullable = true)\n",
      " |-- LTV Ratio: double (nullable = true)\n",
      " |-- Profile Score: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_num.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1990fa1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Credit History Length</th>\n",
       "      <th>Number of Existing Loans</th>\n",
       "      <th>Loan Amount</th>\n",
       "      <th>Loan Tenure</th>\n",
       "      <th>Existing Customer</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>LTV Ratio</th>\n",
       "      <th>Employment Profile</th>\n",
       "      <th>Profile Score</th>\n",
       "      <th>Occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>Male</td>\n",
       "      <td>36000</td>\n",
       "      <td>604</td>\n",
       "      <td>487</td>\n",
       "      <td>5</td>\n",
       "      <td>109373</td>\n",
       "      <td>221</td>\n",
       "      <td>No</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Mysuru</td>\n",
       "      <td>90.943430</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>77</td>\n",
       "      <td>Doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>Male</td>\n",
       "      <td>50000</td>\n",
       "      <td>447</td>\n",
       "      <td>386</td>\n",
       "      <td>2</td>\n",
       "      <td>150000</td>\n",
       "      <td>89</td>\n",
       "      <td>No</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>91.135253</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>43</td>\n",
       "      <td>Software Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>Other</td>\n",
       "      <td>178000</td>\n",
       "      <td>850</td>\n",
       "      <td>503</td>\n",
       "      <td>10</td>\n",
       "      <td>69099</td>\n",
       "      <td>110</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Kanpur</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>90</td>\n",
       "      <td>Banker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69</td>\n",
       "      <td>Female</td>\n",
       "      <td>46000</td>\n",
       "      <td>668</td>\n",
       "      <td>349</td>\n",
       "      <td>6</td>\n",
       "      <td>150000</td>\n",
       "      <td>148</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>87.393365</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>86</td>\n",
       "      <td>Contractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>Male</td>\n",
       "      <td>132000</td>\n",
       "      <td>601</td>\n",
       "      <td>553</td>\n",
       "      <td>5</td>\n",
       "      <td>150000</td>\n",
       "      <td>157</td>\n",
       "      <td>No</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Mysuru</td>\n",
       "      <td>66.158757</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>90</td>\n",
       "      <td>Teacher</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Income  Credit Score  Credit History Length  \\\n",
       "0   31    Male   36000           604                    487   \n",
       "1   25    Male   50000           447                    386   \n",
       "2   62   Other  178000           850                    503   \n",
       "3   69  Female   46000           668                    349   \n",
       "4   52    Male  132000           601                    553   \n",
       "\n",
       "   Number of Existing Loans  Loan Amount  Loan Tenure Existing Customer  \\\n",
       "0                         5       109373          221                No   \n",
       "1                         2       150000           89                No   \n",
       "2                        10        69099          110               Yes   \n",
       "3                         6       150000          148               Yes   \n",
       "4                         5       150000          157                No   \n",
       "\n",
       "           State       City  LTV Ratio Employment Profile  Profile Score  \\\n",
       "0      Karnataka     Mysuru  90.943430           Salaried             77   \n",
       "1      Karnataka  Bengaluru  91.135253           Salaried             43   \n",
       "2  Uttar Pradesh     Kanpur  40.000000           Salaried             90   \n",
       "3      Karnataka  Bengaluru  87.393365      Self-Employed             86   \n",
       "4      Karnataka     Mysuru  66.158757           Salaried             90   \n",
       "\n",
       "          Occupation  \n",
       "0             Doctor  \n",
       "1  Software Engineer  \n",
       "2             Banker  \n",
       "3         Contractor  \n",
       "4            Teacher  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd=df.toPandas()\n",
    "df_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0971c5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "sns.boxplot(x=df_pd['Loan Amount'],y=df_pd['Gender'],hue=df_pd['Employment Profile']);\n",
    "plt.ylabel('Gender',fontsize=20);\n",
    "plt.xlabel('Loan Amount',fontsize=20);\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(bbox_to_anchor=(1, 1),fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b82c017b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Age', ylabel='Loan Amount'>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x=df_pd['Age'],y=df_pd['Loan Amount'],ci=None,estimator='median'\n",
    "           # , kind=\"line\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f60c403b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Gender', 'Income', 'Credit Score', 'Credit History Length',\n",
       "       'Number of Existing Loans', 'Loan Amount', 'Loan Tenure',\n",
       "       'Existing Customer', 'State', 'City', 'LTV Ratio', 'Employment Profile',\n",
       "       'Profile Score', 'Occupation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ec64cd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Income', ylabel='Loan Amount'>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/01 21:40:13 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 1025846 ms exceeds timeout 120000 ms\n",
      "23/10/01 21:40:13 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "23/10/01 21:40:13 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/01 21:40:13 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/01 22:14:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/01 22:14:40 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/01 22:46:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/01 22:46:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/01 23:19:43 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/01 23:19:43 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/01 23:53:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/01 23:53:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 00:26:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 00:26:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 00:58:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 00:58:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 01:16:20 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 01:16:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 01:49:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 01:49:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 02:24:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 02:24:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 02:57:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 02:57:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 03:29:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 03:29:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 04:02:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 04:02:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 04:34:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 04:34:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 04:52:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 04:52:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 05:24:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/02 05:24:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/02 05:41:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/02 05:41:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 06:11:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/02 06:11:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/02 06:46:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/02 06:46:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 07:20:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 07:20:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 07:51:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 07:51:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 08:24:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 08:24:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 08:58:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 08:58:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:29:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:29:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:29:27 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:29:27 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:29:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:29:37 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:29:47 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:29:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:29:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:29:57 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:30:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:30:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:30:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:30:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:30:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:30:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:30:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:30:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:30:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:30:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:30:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/02 09:30:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/02 09:31:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:31:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:31:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/02 09:31:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/02 09:31:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/02 09:31:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:31:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/02 09:31:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/02 09:31:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:31:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:31:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/02 09:31:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/02 09:32:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:32:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:32:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:32:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:32:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:32:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:32:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:32:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:32:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:32:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:32:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:32:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:33:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:33:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:33:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:33:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:33:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:33:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:33:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:33:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 09:33:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/02 09:33:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.59.101:59794\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    }
   ],
   "source": [
    "sns.lineplot(x=df_pd['Income'],y=df_pd['Loan Amount'],ci=None,estimator='median'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7023524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
