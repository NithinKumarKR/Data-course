{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d35a6c27",
   "metadata": {},
   "source": [
    "# Medical Cost Personal Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea8200",
   "metadata": {},
   "source": [
    "# Data Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043c25c7",
   "metadata": {},
   "source": [
    "\n",
    "About Dataset\n",
    "Context\n",
    "Machine Learning with R by Brett Lantz is a book that provides an introduction to machine learning using R. As far as I can tell, Packt Publishing does not make its datasets available online unless you buy the book and create a user account which can be a problem if you are checking the book out from the library or borrowing the book from a friend. All of these datasets are in the public domain but simply needed some cleaning up and recoding to match the format in the book.\n",
    "\n",
    "Content\n",
    "Columns\n",
    "\n",
    "age: age of primary beneficiary\n",
    "\n",
    "sex: insurance contractor gender, female, male\n",
    "\n",
    "bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height,\n",
    "objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n",
    "\n",
    "children: Number of children covered by health insurance / Number of dependents\n",
    "\n",
    "smoker: Smoking\n",
    "\n",
    "region: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n",
    "\n",
    "charges: Individual medical costs billed by health insurance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750f01bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "import scipy.stats as st\n",
    "import pylab\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#loading the dataset\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "spark = SparkSession.builder.appName(\"example\").config(\"spark.log.level\", \"DEBUG\").getOrCreate()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pyspark.ml.feature import QuantileDiscretizer\n",
    "from pyspark.sql.functions import col, lit, concat_ws\n",
    "from pyspark.sql.functions import when ,concat,lit , round, mean ,median\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f0f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv(\"/Users/nithinkumar/Downloads/insurance.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d431308d",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c6109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the shape of the dataset\n",
    "print(\"Remaining columns:\", len(df.columns))\n",
    "print(\"Number of rows:\", df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425a2801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the columns of the dataset\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253068dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#null values count\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "null_counts = []\n",
    "\n",
    "# Iterate over all columns in the DataFrame\n",
    "for col_name in df.columns:\n",
    "    # Count the number of null values for each column\n",
    "    null_count = df.where(col(col_name).isNull()).count()\n",
    "    # Append the result to the list\n",
    "    null_counts.append((col_name, null_count))\n",
    "\n",
    "# Display the null counts for each column\n",
    "for col_name, count in null_counts:\n",
    "    print(f\"Column : '{col_name}' has {count} null values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd98a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#column data types\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a461465",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dulicate values\n",
    "df=df.dropDuplicates()\n",
    "#checking the shape of the dataset\n",
    "print(\"Remaining columns:\", len(df.columns))\n",
    "print(\"Number of rows:\", df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d7bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd=df.describe().toPandas()\n",
    "df_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cf7e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols=[]\n",
    "catorical_cols=[]\n",
    "for cols in df.columns:\n",
    "    (catorical_cols.append(cols) if df.select(cols).dtypes[0][1]=='string' else numerical_cols.append(cols))\n",
    "df_num=df.select(numerical_cols)\n",
    "df_cat=df.select(catorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f54c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59188dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33f00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select([col(column).alias(column.strip()) for column in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4742120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd=df.toPandas()\n",
    "df_pd.corr()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6524d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca6e2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PiePlot(Col_name):\n",
    "    df_modified=df.groupBy(col(Col_name).alias(Col_name)).count()\n",
    "    df_modified=df_modified.toPandas()\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.pie(df_modified['count'],labels=df_modified[Col_name],autopct='%.2f%%',radius=1\n",
    "           ,wedgeprops=dict(width=.5)\n",
    "            ,pctdistance=.75\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e670ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def barh(Col_name,x_Col_name,y_label,x_label,type_bar='H'):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    df_modified=df.groupBy(col(Col_name).alias(Col_name)).count()\n",
    "    df_modified=df_modified.orderBy('count',ascending=False)\n",
    "    df_modified=df_modified.toPandas()\n",
    "    df_modified['count']=df_modified['count']/sum(df_modified['count'])*100\n",
    "    df_modified=df_modified.head(10)\n",
    "    if type_bar=='H':\n",
    "        sns.barplot(y=df_modified[Col_name],x=df_modified[x_Col_name]);\n",
    "        for i, val in enumerate(df_modified.index):\n",
    "            y = df_modified['count'].loc[val].sum()\n",
    "            #print(y.dtype)\n",
    "            plt.text( y+1, i,str(int(y))+'%', ha=\"center\",fontsize = 15,         color ='black')\n",
    "    else :\n",
    "        sns.barplot(x=df_modified[Col_name],y=df_modified[x_Col_name]);\n",
    "        for i, val in enumerate(df_modified.index):\n",
    "            y = df_modified['count'].loc[val].sum()\n",
    "            plt.text(i, y ,str(int(y))+'%' , ha=\"center\",fontsize = 15,         color ='black')\n",
    "\n",
    "    plt.ylabel(y_label,fontsize=10);\n",
    "    plt.xlabel(x_label,fontsize=10);\n",
    "    # Add legend outside the plot\n",
    "    plt.legend(bbox_to_anchor=(1, 1));\n",
    "    plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d795a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bins(n,Col_name,Extra_Filter,x_label,y_label,plot):\n",
    "\n",
    "    quantileDiscretizer=QuantileDiscretizer(numBuckets=n,inputCol=Col_name,outputCol='Col_bin')\n",
    "    model=quantileDiscretizer.fit(df)\n",
    "    df_Age_with_bins=model.transform(df)\n",
    "    bin_edges = model.getSplits()\n",
    "\n",
    "    bin_edges.pop()\n",
    "    bin_edges.pop(0)\n",
    "    bin_edges.insert(0,float(df_Age_with_bins.select(F.min(Col_name)).collect()[0][0]))\n",
    "    if bin_edges[-1]!=float(df_Age_with_bins.select(F.max(Col_name)).collect()[0][0]):\n",
    "        bin_edges.append(float(df_Age_with_bins.select(F.max(Col_name)).collect()[0][0]))\n",
    "    bin_edges=[ int(i) for i in bin_edges]\n",
    "    #print(len(bin_edges))\n",
    "    if len(bin_edges)==5:\n",
    "        return Bins(n+1,Col_name,Extra_Filter,x_label,y_label,plot)\n",
    "    \n",
    "    # Create a new column based on bin edges\n",
    "    # Create a new column based on bin edges\n",
    "    df_Age_with_bins = model.transform(df).withColumn(\n",
    "        'Col_bin',\n",
    "    #    when(df['Age'] <= bin_edges[0], lit(str(bin_edges[0]))).\n",
    "        when((df[Col_name] >=bin_edges[0]) & (df[Col_name] < bin_edges[1]),\\\n",
    "              concat(lit(str(bin_edges[0])),lit('-'),lit(str(bin_edges[1]))))\n",
    "        .when((df[Col_name] >= bin_edges[1]) & (df[Col_name] < bin_edges[2]), \\\n",
    "              concat(lit(str(bin_edges[1])),lit('-'),lit(str(bin_edges[2]))))\n",
    "        .when((df[Col_name] >= bin_edges[2]) & (df[Col_name] < bin_edges[3]),\\\n",
    "              concat(lit(str(bin_edges[2])),lit('-'),lit(str(bin_edges[3]))))\n",
    "        .when((df[Col_name] >= bin_edges[3]) & (df[Col_name] < bin_edges[4]), \\\n",
    "              concat(lit(str(bin_edges[3])),lit('-'),lit(str(bin_edges[4]))))\n",
    "        .otherwise(concat(lit(str(bin_edges[4])),lit('-'),lit(str(bin_edges[5]))))  # Handle values greater than the last bin edge\n",
    "    )\n",
    "    df_Age_with_bins = df_Age_with_bins.groupBy('Col_bin',Extra_Filter)\\\n",
    "    .agg(round(median(\"charges\")).alias(\"Loan_Amount\"))\n",
    "    df_Age_with_bins=df_Age_with_bins.orderBy('Loan_Amount')\n",
    "    df_Age_with_bins=df_Age_with_bins.toPandas()\n",
    "    plt.figure(figsize=(10,3));\n",
    "\n",
    "    if plot=='point':\n",
    "        sns.pointplot(x=df_Age_with_bins.Col_bin,y=df_Age_with_bins.Loan_Amount\n",
    "                     ,hue=df_Age_with_bins[Extra_Filter]);\n",
    "    elif plot=='rel':\n",
    "        sns.relplot(x=df_Age_with_bins.Col_bin,y=df_Age_with_bins.Loan_Amount\n",
    "                     ,hue=df_Age_with_bins[Extra_Filter]);    \n",
    "    elif plot=='scatter':\n",
    "        sns.scatterplot(x=df_Age_with_bins.Col_bin,y=df_Age_with_bins.Loan_Amount\n",
    "                     ,hue=df_Age_with_bins[Extra_Filter]) ;\n",
    "    else:\n",
    "        sns.lineplot(x=df_Age_with_bins.Col_bin,y=df_Age_with_bins.Loan_Amount\n",
    "                     ,hue=df_Age_with_bins[Extra_Filter]);\n",
    "    plt.xlabel(x_label,fontsize=10);\n",
    "    plt.ylabel(y_label,fontsize=10);\n",
    "    # Add legend outside the plot\n",
    "    #plt.legend(bbox_to_anchor=(1, 1));\n",
    "    plt.xticks(fontsize=10);\n",
    "    plt.yticks(fontsize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12ff405",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868385e6",
   "metadata": {},
   "source": [
    "# Understanding of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b43e598",
   "metadata": {},
   "outputs": [],
   "source": [
    "PiePlot('sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6bf155",
   "metadata": {},
   "outputs": [],
   "source": [
    "PiePlot('smoker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed37652",
   "metadata": {},
   "outputs": [],
   "source": [
    "barh('children','count','childrens','Number of Customers','K');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c4c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "barh('region','count','region','Number of Customers','K');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa8f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bea950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bins(5,'age','sex','Age-Bin','charges','line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7149f5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bins(5,'age','smoker','Age-Bin','charges','scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec94384",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bins(5,'age','children','Age-Bin','charges','point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1e44dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bins(5,'age','region','Age-Bin','region','rel');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd38eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bins(5,'bmi','sex','Bmi-Bin','Charges','line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10856a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bins(5,'bmi','smoker','Bmi-Bin','Charges','scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9100b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bins(5,'bmi','children','Bmi-Bin','Charges','point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac55470",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bins(5,'bmi','region','Bmi-Bin','region','rel');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16363cf4",
   "metadata": {},
   "source": [
    "# Based on the information provided, here are some key points for Exploratory Data Analysis (EDA):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e74d5ac",
   "metadata": {},
   "source": [
    "Demographic Analysis:\n",
    "Gender Distribution:\n",
    "\n",
    "Almost equal representation of customers from both genders.\n",
    "Smoker vs. Non-Smoker:\n",
    "\n",
    "The majority of customers are non-smokers (80%), while 20% are smokers.\n",
    "Smokers tend to have higher charges, except in the 24-34 age group where charges are comparable between smokers and non-smokers.\n",
    "Children Distribution:\n",
    "\n",
    "42% of customers have no children.\n",
    "For customers aged 18-24, those with 4 children are more than those with 2 children.\n",
    "In the 34-44 age group, customers with 4 children outnumber those with 5 children.\n",
    "Age-Based Analysis:\n",
    "Age Groups:\n",
    "\n",
    "Charges are consistent across regions, indicating that pricing is primarily age-dependent rather than region-dependent.\n",
    "Charges are notably lower for the 24-34 and 44-54 age groups.\n",
    "Age and Gender:\n",
    "\n",
    "Females generally incur higher charges than males, except in the 24-34 age group where charges are equal.\n",
    "Smokers in the 24-34 age group have lower charges compared to other age bins.\n",
    "BMI Analysis:\n",
    "BMI and Gender:\n",
    "\n",
    "Females are charged more for BMI in the range of 15-28, while males are charged more for BMI above 28.\n",
    "BMI and Region:\n",
    "\n",
    "Southeast charges more for BMI in the range of 15-28, and the Northeast charges more for BMI above 28.\n",
    "Children Analysis:\n",
    "Children and Age:\n",
    "\n",
    "For customers aged 15-25, those with 4 children are charged more than those with 2 children.\n",
    "In the 25-28 age group, charges follow the order: 3>5>2>1>4>0.\n",
    "Children and Region:\n",
    "\n",
    "For customers with BMI in the range of 15-28, the Southeast charges more, while for BMI above 32, the Southeast charges less.\n",
    "\n",
    "Overall:\n",
    "\n",
    "No Children Data for 15-25 Age Group:\n",
    "\n",
    "No data available for customers with no children in the 15-25 age group.\n",
    "Consistent Charges in Certain Age Groups:\n",
    "\n",
    "Charges remain consistent for certain age groups, irrespective of the number of children or region.\n",
    "Smoker Charges Anomaly in 24-34 Age Group:\n",
    "\n",
    "An anomaly where smokers in the 24-34 age group have lower charges compared to other age groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29ac9ab",
   "metadata": {},
   "source": [
    "The customers from both gender is almost equal\n",
    "The customers having less Non-smoker(80%) compare to smoker(20%)\n",
    "The customers are more with no childrens.\n",
    "42 % - No children\n",
    "24 % - 1 children\n",
    "17 % - 2 children\n",
    "11 % - 3 children\n",
    "1 % - 4 children\n",
    "1 % - 5 children\n",
    "Please refer the below regions with there percentage.\n",
    "27% - SounthEast , 24%- other region \n",
    "For Every age Female charges little more then male but at the 24- 34 both changed same.\n",
    "The charges on the smoker is more then non-smoker but 24-34 the charges are less compared to othr age bins\n",
    "At the Ages from 18-24:\n",
    "1.For the children with 4 childrens are more then 2 childrens\n",
    "2.but on same age for 3 and 5 charges same prices  and childrens betwee 0 and 1 are both are sam\n",
    "At the Ages from 34-44:\n",
    "1.For the children with 4 childrens are more then 5 childrens\n",
    "2.but on same age with 1,2,3,0 are charging same price.\n",
    "At the 24-34 and 44-54 ages\n",
    "They are charging same for all.\n",
    "REgion :\n",
    "for all the region price depends on Age not region to much\n",
    "\n",
    "BMI:\n",
    "\n",
    "For the Female they are charging more for 15-28 BMI\n",
    "For the Male they are charging more above 28 BMI\n",
    "Smoker:\n",
    "from 15-28  they are changing less then BMI which is more 28+\n",
    "Childrens:\n",
    "15-25:1.We don;t have any data for customer with no childrens?\n",
    "\t\t2.For the other customer with who having 5,3,1 charging more.\n",
    "\t\t3.Customer with 4 childrens charing more in this.\n",
    "25-28: The follows charges for childrens 3>5>2>1>4>0\n",
    "28-32: The follows charges for childrens 0,3>4>2>1>5\n",
    "32-35:The follows charges for childrens 4>3,2,0>1>5\n",
    "35-53: The follows charges for childrens 3>0,2,4>1,5\n",
    "Region:\n",
    "15-28:  Southeast is more charged and above this bmi northeast charges mored\n",
    "for 32+ the southeast is charging less\n",
    "25-28 : north east is less\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d14870",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5b91a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_df=df\n",
    "result_df1=result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=result_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec460add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cf3e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def One_Hot_Ender(inputCol_name,OutputCol_name,alias_name,df):\n",
    "    from pyspark.sql.functions import collect_list\n",
    "    df_values={}\n",
    "    indexer=StringIndexer(inputCol=inputCol_name,outputCol=OutputCol_name)\n",
    "    indexer_model = indexer.fit(df)\n",
    "    df = indexer_model.transform(df)\n",
    "    indexed_labels = indexer_model.labels\n",
    "    for label, index in zip(indexed_labels, range(len(indexed_labels))):\n",
    "        df_values[label]=index\n",
    "#    df=df.drop(inputCol_name)\n",
    "   # df=df.withColumnRenamed(OutputCol_name,inputCol_name)\n",
    "    return df,df_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d47211",
   "metadata": {},
   "outputs": [],
   "source": [
    "df,df_values=One_Hot_Ender('sex','sexs','gen',df)\n",
    "df_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b989972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b6c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8534b83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.withColumnRenamed('sexs','sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4387b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94bee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d772a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df,df_values=One_Hot_Ender('region','regions','reg',df)\n",
    "df_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f1cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f9f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('region')\n",
    "df=df.withColumnRenamed('regions','region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f1ddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427cb1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_mapping = df.select('smoker').distinct().rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e1d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4fae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_mapping=dict(zip(ordinal_mapping,[0,1]))\n",
    "ordinal_encoder=udf(lambda category:ordinal_mapping[category],IntegerType())\n",
    "df = df.withColumn(\"smokers\", ordinal_encoder(col(\"smoker\")))\n",
    "#df=df.drop(\"smoker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7190a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201ef6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(\"smoker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869cd5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b7b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "selected_columns=list(df.columns)\n",
    "vector_Assembler=VectorAssembler(inputCols=df.columns,outputCol='features')\n",
    "df_assembled=vector_Assembler.transform(df).select('features')\n",
    "#print(df_assembled.show(5))\n",
    "correlation_matrix = Correlation.corr(df_assembled, \"features\").head()\n",
    "#print(correlation_matrix)\n",
    "correlation_matrix = correlation_matrix[0].toArray()[selected_columns.index('charges')]\n",
    "columns = ['Column', 'Correlation with Loan Amount']\n",
    "data = dict(zip(selected_columns, correlation_matrix))\n",
    "for column, correlation in data.items():\n",
    "    print(f\"{column}: {correlation*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6987fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(*['charges']).toPandas()\n",
    "y=df.select('charges').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0e28d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d611288",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c9f0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ea2033",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,train_size=.8,random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67c1e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4edddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.corr()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d051f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(dataset,threhold):\n",
    "    col_corr=set()\n",
    "    corr_matrix=dataset.corr()*100\n",
    "    #print(corr_matrix)\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i,j])>threhold:\n",
    "                colname=corr_matrix.columns[i]\n",
    "                #print(colname)\n",
    "                col_corr.add(colname)\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abfa55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(x_train,70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d42e47b",
   "metadata": {},
   "source": [
    "# Feature Scaling or Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed82570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee781ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112b5d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d2fc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled=scaler.fit_transform(x_train)\n",
    "x_test_scaled=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3f47fb",
   "metadata": {},
   "source": [
    "# BOX PLOTS TO UNDERSTAND EFFECT OF STANDARD SCALER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dded75d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "sns.boxplot(x_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5b367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "sns.boxplot(x_test_scaled);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8559bfb",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a672477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_absolute_percentage_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744f2401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regression=LinearRegression()\n",
    "regression.fit(x_train_scaled,y_train)\n",
    "y_pred=regression.predict(x_test_scaled)\n",
    "mae=mean_absolute_error(y_test,y_pred)\n",
    "mape=mean_absolute_percentage_error(y_pred,y_test)\n",
    "mse=mean_squared_error(y_pred,y_test)\n",
    "score=r2_score(y_pred,y_test)\n",
    "print(mae,mape,mse,score)\n",
    "plt.scatter(y_pred,y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3d778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "regression=Lasso()\n",
    "regression.fit(x_train_scaled,y_train)\n",
    "y_pred=regression.predict(x_test_scaled)\n",
    "mae=mean_absolute_error(y_test,y_pred)\n",
    "mape=mean_absolute_percentage_error(y_pred,y_test)\n",
    "mse=mean_squared_error(y_pred,y_test)\n",
    "score=r2_score(y_pred,y_test)\n",
    "print(mae,mape,mse,score)\n",
    "plt.scatter(y_pred,y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c5f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "regression=LassoCV(cv=5)\n",
    "regression.fit(x_train_scaled,y_train)\n",
    "y_pred=regression.predict(x_test_scaled)\n",
    "mae=mean_absolute_error(y_test,y_pred)\n",
    "mape=mean_absolute_percentage_error(y_pred,y_test)\n",
    "mse=mean_squared_error(y_pred,y_test)\n",
    "score=r2_score(y_pred,y_test)\n",
    "print(mae,mape,mse,score)\n",
    "plt.scatter(y_pred,y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4eea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "regression=Ridge()\n",
    "regression.fit(x_train_scaled,y_train)\n",
    "y_pred=regression.predict(x_test_scaled)\n",
    "mae=mean_absolute_error(y_test,y_pred)\n",
    "mape=mean_absolute_percentage_error(y_pred,y_test)\n",
    "mse=mean_squared_error(y_pred,y_test)\n",
    "score=r2_score(y_pred,y_test)\n",
    "print(mae,mape,mse,score)\n",
    "plt.scatter(y_pred,y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feee54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "regression=RidgeCV(cv=5)\n",
    "regression.fit(x_train_scaled,y_train)\n",
    "y_pred=regression.predict(x_test_scaled)\n",
    "mae=mean_absolute_error(y_test,y_pred)\n",
    "mape=mean_absolute_percentage_error(y_pred,y_test)\n",
    "mse=mean_squared_error(y_pred,y_test)\n",
    "score=r2_score(y_pred,y_test)\n",
    "print(mae,mape,mse,score)\n",
    "plt.scatter(y_pred,y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af5edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ff6e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "regression=ElasticNet()\n",
    "regression.fit(x_train_scaled,y_train)\n",
    "y_pred=regression.predict(x_test_scaled)\n",
    "mae=mean_absolute_error(y_test,y_pred)\n",
    "mape=mean_absolute_percentage_error(y_pred,y_test)\n",
    "mse=mean_squared_error(y_pred,y_test)\n",
    "score=r2_score(y_pred,y_test)\n",
    "print(mae,mape,mse,score)\n",
    "plt.scatter(y_pred,y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bcf912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "regression=ElasticNetCV(cv=5)\n",
    "regression.fit(x_train_scaled,y_train)\n",
    "y_pred=regression.predict(x_test_scaled)\n",
    "mae=mean_absolute_error(y_test,y_pred)\n",
    "mape=mean_absolute_percentage_error(y_pred,y_test)\n",
    "mse=mean_squared_error(y_pred,y_test)\n",
    "score=r2_score(y_pred,y_test)\n",
    "print(mae,mape,mse,score)\n",
    "plt.scatter(y_pred,y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7ed8ec",
   "metadata": {},
   "source": [
    "# Pickle the Ml models , prepressin model Standscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d53fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63a1b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c28487",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(scaler,open('scaler.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6720255",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(regression,open('ridge.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6844222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_state_from_ip(ip):\n",
    "    try:\n",
    "        response = requests.get(f'https://ipinfo.io/{ip}/json', timeout=100)\n",
    "        data = response.json()\n",
    "        city = data.get('city', 'N/A')\n",
    "        region = data.get('region', 'N/A')\n",
    "        latitude = data.get('latitude', 'N/A')\n",
    "        longitude = data.get('longitude', 'N/A')\n",
    "        postal = data.get('postal', 'N/A')\n",
    "        return state,city,region,latitude,longitude,postal\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "ip_address = '49.37.232.202'\n",
    "get_state_from_ip(ip_address)\n",
    "#state\n",
    "#if state:\n",
    "   # print(f\"The state for IP address {ip_address} is: {state}\")\n",
    "#else:\n",
    "    #print(f\"Unable to determine the state for IP address {ip_address}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef08d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \"ip\": \"49.14.101.16\",\n",
    "  \"city\": \"Delhi\",\n",
    "  \"region\": \"Delhi\",\n",
    "  \"country\": \"IN\",\n",
    "  \"loc\": \"28.6519,77.2315\",\n",
    "  \"org\": \"AS45271 Idea Cellular Limited\",\n",
    "  \"postal\": \"110001\",\n",
    "  \"timezone\": \"Asia/Kolkata\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5adecff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"CSV to Parquet\").getOrCreate()\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "csv_file_path = \"/Users/nithinkumar/Downloads/df1.csv\"\n",
    "\n",
    "# Read CSV into a DataFrame\n",
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(csv_file_path)\n",
    "\n",
    "# Repartition the DataFrame to have a single partition\n",
    "df = df.repartition(1)\n",
    "\n",
    "# Specify the path where you want to save the Parquet file\n",
    "parquet_output_path = \"/Users/nithinkumar/Downloads/acs.parquet\"\n",
    "\n",
    "# Write the DataFrame to Parquet format\n",
    "df.write.parquet(parquet_output_path)\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8be20f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
